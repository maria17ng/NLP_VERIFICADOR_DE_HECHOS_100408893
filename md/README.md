# Sistema de VerificaciÃ³n de Hechos con RAG

> **Proyecto Final - Procesamiento del Lenguaje Natural**
> MÃ¡ster en Inteligencia Artificial Aplicada - UC3M
> Curso 2025/2026

## ğŸ“‹ DescripciÃ³n

Sistema de verificaciÃ³n automÃ¡tica de hechos basado en **Retrieval-Augmented Generation (RAG)** que determina la veracidad de afirmaciones utilizando una base de datos documental especÃ­fica. El sistema recupera evidencia relevante mediante bÃºsqueda semÃ¡ntica y emplea un LLM para evaluar las afirmaciones.

### âœ¨ CaracterÃ­sticas Principales

- âœ… **VerificaciÃ³n automÃ¡tica**: Clasifica afirmaciones como VERDADERO, FALSO o NO SE PUEDE VERIFICAR
- ğŸŒ **Soporte multilingÃ¼e**: Acepta consultas en espaÃ±ol, inglÃ©s, francÃ©s, alemÃ¡n, italiano y portuguÃ©s
- ğŸ“š **Base de datos vectorial**: Utiliza ChromaDB para almacenamiento y recuperaciÃ³n eficiente
- ğŸ¯ **Reranking inteligente**: Mejora la precisiÃ³n con modelos cross-encoder
- ğŸ’¾ **Sistema de cachÃ©**: Optimiza consultas repetidas
- ğŸ“– **Citaciones precisas**: Proporciona fuentes exactas (pÃ¡gina/secciÃ³n) de la evidencia
- ğŸ“Š **Nivel de confianza**: Indica la certeza del veredicto (0-5)
- ğŸ” **Logging completo**: Registro detallado de todas las operaciones

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Usuario         â”‚
â”‚ (AfirmaciÃ³n)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Procesador MultilingÃ¼e                  â”‚
â”‚ - DetecciÃ³n de idioma                   â”‚
â”‚ - TraducciÃ³n a espaÃ±ol                  â”‚
â”‚ - ValidaciÃ³n de calidad                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sistema RAG                             â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ 1. BÃºsqueda Vectorial (k=50)        â”‚â”‚
â”‚ â”‚    - Similitud semÃ¡ntica            â”‚â”‚
â”‚ â”‚    - Embeddings multilingÃ¼es        â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ 2. Reranking (top_k=5)              â”‚â”‚
â”‚ â”‚    - Cross-encoder                  â”‚â”‚
â”‚ â”‚    - Refinamiento de relevancia     â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ 3. GeneraciÃ³n con LLM               â”‚â”‚
â”‚ â”‚    - Prompt few-shot                â”‚â”‚
â”‚ â”‚    - Formato JSON estructurado      â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Respuesta MultilingÃ¼e                   â”‚
â”‚ - Veredicto traducido                   â”‚
â”‚ - ExplicaciÃ³n                           â”‚
â”‚ - Fuentes citadas                       â”‚
â”‚ - Nivel de confianza                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Requisitos Funcionales

El sistema cumple con todos los requisitos obligatorios especificados en el proyecto:

### âœ… Requisitos Implementados

1. **Respuesta clara sobre veracidad**: El sistema proporciona veredictos explÃ­citos (VERDADERO/FALSO/NO SE PUEDE VERIFICAR)

2. **CitaciÃ³n de fuentes**: Las respuestas incluyen:
   - Nombre del documento fuente
   - UbicaciÃ³n especÃ­fica (pÃ¡gina para PDFs, secciÃ³n para TXT)
   - Fragmento de evidencia citado

3. **Manejo de informaciÃ³n insuficiente**: Cuando no hay evidencia, el sistema responde "NO SE PUEDE VERIFICAR" sin inventar informaciÃ³n

4. **Respuesta en el idioma original**: Las respuestas se traducen automÃ¡ticamente al idioma de la consulta

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- Python 3.9+
- Ollama instalado (para LLM local)
- 8GB+ RAM recomendado

### 1. Clonar el repositorio

```bash
git clone <url-del-repositorio>
cd verificador
```

### 2. Crear entorno virtual

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Descargar modelo de detecciÃ³n de idioma

```bash
# Descargar lid.176.ftz de FastText
wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz
```

### 5. Configurar Ollama

```bash
# Instalar Ollama: https://ollama.ai/
ollama pull llama3.2
```

## âš™ï¸ ConfiguraciÃ³n

El archivo `config.yaml` contiene toda la configuraciÃ³n del sistema:

```yaml
# Modelos
models:
  llm:
    name: "llama3.2"
    temperature: 0.1  # Bajo para mayor determinismo

  embeddings:
    name: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

  reranker:
    name: "cross-encoder/mmarco-mMiniLMv2-L12-H384-v1"

# RAG
rag:
  similarity_search:
    k: 50  # Documentos iniciales
  reranking:
    top_k: 5  # Documentos finales
  chunking:
    chunk_size: 1000
    chunk_overlap: 200
```

### ConfiguraciÃ³n para Servidores UC3M

Para usar los LLMs desplegados en UC3M, descomentar en `config.yaml`:

```yaml
models:
  llm:
    name: "llama3.1:8b"
    base_url: "https://yiyuan.tsc.uc3m.es"
    api_key: "sk-af55e7023913527f0d96c038eec2ef2d"
```

## ğŸ“š Uso

### 1. Preparar Base de Datos

#### OpciÃ³n A: Descargar desde Wikipedia

```bash
python download_wiki.py
```

Editar la lista de temas en `download_wiki.py`:

```python
temas_a_descargar = [
    "Real Madrid Club de FÃºtbol",
    "Cambio climÃ¡tico",
    "Inteligencia artificial",
    "COVID-19"
]
```

#### OpciÃ³n B: AÃ±adir documentos propios

Colocar archivos `.txt` o `.pdf` en `data/raw/`

### 2. Ingestar Documentos

```bash
# Ingesta bÃ¡sica
python ingest_data.py

# Con opciones avanzadas
python ingest_data.py --clear  # Limpiar BD existente primero
python ingest_data.py --data-path /ruta/custom --db-path /ruta/bd

# Ver estadÃ­sticas de la BD
python ingest_data.py --stats
```

### 3. Verificar Hechos

```python
from verifier import FactChecker

# Inicializar verificador
checker = FactChecker()

# Verificar afirmaciÃ³n
resultado = checker.verify("El Real Madrid se fundÃ³ en 1902")

print(resultado)
# {
#   "veredicto": "VERDADERO",
#   "nivel_confianza": 5,
#   "fuente_documento": "Real_Madrid_Club_de_FÃºtbol.txt",
#   "explicacion_corta": "El documento confirma la fundaciÃ³n en 1902...",
#   "evidencia_citada": "fue fundado oficialmente el 6 de marzo de 1902",
#   "tiempo_procesamiento": "2.34s",
#   "origen": "LLM",
#   "idioma_respuesta": "es"
# }
```

### Ejemplos de Uso

#### Ejemplo 1: Consulta en inglÃ©s

```python
resultado = checker.verify("Real Madrid plays at the Santiago Bernabeu Stadium")
# Respuesta en inglÃ©s con evidencia del corpus
```

#### Ejemplo 2: Sin evidencia

```python
resultado = checker.verify("La tecnologÃ­a 5G causa cÃ¡ncer")
# {
#   "veredicto": "NO SE PUEDE VERIFICAR",
#   "nivel_confianza": 0,
#   "explicacion_corta": "No se encontrÃ³ informaciÃ³n relevante..."
# }
```

#### Ejemplo 3: Consulta en francÃ©s

```python
resultado = checker.verify("Le Real Madrid a Ã©tÃ© fondÃ© en 1902")
# Respuesta en francÃ©s con evidencia traducida
```

## ğŸ“Š Estructura del Proyecto

```
verificador/
â”œâ”€â”€ config.yaml              # ConfiguraciÃ³n del sistema
â”œâ”€â”€ requirements.txt         # Dependencias Python
â”œâ”€â”€ README.md               # DocumentaciÃ³n
â”œâ”€â”€ .gitignore              # Archivos ignorados por git
â”‚
â”œâ”€â”€ verifier.py             # Sistema principal de verificaciÃ³n
â”œâ”€â”€ ingest_data.py          # Ingesta de documentos a BD vectorial
â”œâ”€â”€ download_wiki.py        # Descarga de artÃ­culos de Wikipedia
â”œâ”€â”€ pipeline_idioma.py      # Procesamiento multilingÃ¼e
â”œâ”€â”€ utils.py                # Utilidades (config, logging)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Documentos fuente (.txt, .pdf)
â”‚   â”œâ”€â”€ vector_store/       # Base de datos vectorial (ChromaDB)
â”‚   â””â”€â”€ prompts/
â”‚       â””â”€â”€ prompts.yaml    # Plantillas de prompts
â”‚
â””â”€â”€ logs/                   # Archivos de log
    â”œâ”€â”€ fact_checker.log
    â””â”€â”€ ingest.log
```

## ğŸ”§ Componentes TÃ©cnicos

### 1. Procesador MultilingÃ¼e (`pipeline_idioma.py`)

- **DetecciÃ³n de idioma**: FastText (lid.176.ftz)
- **TraducciÃ³n**: Google Translator
- **ValidaciÃ³n**: Back-translation para verificar calidad
- **Idiomas soportados**: es, en, fr, de, it, pt

### 2. Sistema RAG (`verifier.py`)

#### Fase de RecuperaciÃ³n

1. **BÃºsqueda vectorial**:
   - Modelo: `paraphrase-multilingual-MiniLM-L12-v2`
   - Recupera top-50 fragmentos por similitud coseno

2. **Reranking**:
   - Modelo: `cross-encoder/mmarco-mMiniLMv2-L12-H384-v1`
   - Refina a top-5 documentos mÃ¡s relevantes

#### Fase de GeneraciÃ³n

- **LLM**: Llama 3.2 (local via Ollama)
- **Temperatura**: 0.1 (determinista pero permite sinÃ³nimos)
- **Estrategia de prompting**: Few-shot learning
- **Formato de salida**: JSON estructurado

### 3. Base de Datos Vectorial (`ingest_data.py`)

- **Motor**: ChromaDB
- **Chunking**: RecursiveCharacterTextSplitter
  - TamaÃ±o: 1000 caracteres
  - Solapamiento: 200 caracteres
- **Metadatos**: UbicaciÃ³n precisa para citaciÃ³n
- **Formatos soportados**: .txt, .pdf

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

El sistema puede evaluarse segÃºn los criterios del proyecto:

### 1. Calidad del Sistema RAG

- **RecuperaciÃ³n de evidencia**: Recall@K, MRR
- **PrecisiÃ³n del veredicto**: Exactitud vs. ground truth
- **Coherencia de respuestas**: BERTScore

### 2. Cobertura Documental

- % de consultas con evidencia suficiente
- DistribuciÃ³n de veredictos

### 3. Tiempo de Respuesta

- Promedio: ~2-3 segundos
- Con cachÃ©: <0.1 segundos

## ğŸ¨ Mejoras Adicionales Implementadas

AdemÃ¡s de los requisitos bÃ¡sicos, el sistema incluye:

### âœ¨ Funcionalidades Avanzadas

1. **Sistema de confianza mejorado**
   - Basado en nÃºmero de fuentes
   - Calidad y longitud del contexto
   - Escala 0-5

2. **CachÃ© inteligente**
   - Basado en hashing semÃ¡ntico
   - GestiÃ³n automÃ¡tica de tamaÃ±o
   - Mejora 10-20x el tiempo de respuesta

3. **Logging profesional**
   - Registro en archivo y consola
   - Niveles configurables
   - Trazabilidad completa

4. **Arquitectura modular**
   - SeparaciÃ³n de responsabilidades
   - ConfiguraciÃ³n externa
   - FÃ¡cil extensiÃ³n y mantenimiento

5. **Soporte multi-formato**
   - PDFs con citaciÃ³n por pÃ¡gina
   - TXT con citaciÃ³n por secciÃ³n
   - Extensible a otros formatos

## ğŸ§ª Pruebas

### Ejecutar pruebas bÃ¡sicas

```bash
python verifier.py
```

### Pruebas personalizadas

```python
from verifier import FactChecker

checker = FactChecker()

# Ver estadÃ­sticas del sistema
stats = checker.get_stats()
print(stats)

# Probar claim
result = checker.verify("Tu afirmaciÃ³n aquÃ­")
```

## ğŸ“ Prompts y OptimizaciÃ³n

El sistema utiliza prompts few-shot en `data/prompts/prompts.yaml`:

```yaml
verification_prompt: |
  ActÃºa como un JUEZ IMPARCIAL de verificaciÃ³n de datos.

  --- EJEMPLOS DE RAZONAMIENTO (APRENDE DE AQUÃ) ---

  [Ejemplos de equivalencia semÃ¡ntica, contradicciÃ³n, etc.]

  --- EVIDENCIA REAL ---
  {context}

  --- AFIRMACIÃ“N REAL ---
  "{claim}"

  Responde ÃšNICAMENTE con JSON.
```

### Estrategias de Prompting

- **Few-shot learning**: 3 ejemplos demostrativos
- **Chain-of-thought implÃ­cito**: El juez razona antes de responder
- **Formato JSON**: Salida estructurada y parseable
- **Temperatura baja (0.1)**: Determinismo con flexibilidad semÃ¡ntica

## ğŸ”’ MitigaciÃ³n de Alucinaciones

El sistema implementa mÃºltiples estrategias anti-alucinaciÃ³n:

1. **RAG estricto**: Solo usa informaciÃ³n de la base de datos
2. **Prompt defensivo**: Indica explÃ­citamente "NO inventar"
3. **OpciÃ³n de abstenciÃ³n**: "NO SE PUEDE VERIFICAR" cuando falta evidencia
4. **Temperatura baja**: Reduce generaciÃ³n creativa
5. **ValidaciÃ³n de traducciÃ³n**: Back-translation para calidad

## ğŸ“š TecnologÃ­as Utilizadas

- **LLM**: Llama 3.2 (vÃ­a Ollama)
- **Framework**: LangChain
- **Embeddings**: Sentence Transformers
- **Reranking**: Cross-Encoder
- **Base de datos**: ChromaDB
- **TraducciÃ³n**: Deep Translator
- **DetecciÃ³n de idioma**: FastText
- **Procesamiento**: PyPDF, LangChain Text Splitters

## ğŸ¤ ContribuciÃ³n

Este es un proyecto acadÃ©mico. Para sugerencias:

1. Revisar issues existentes
2. Proponer mejoras mediante pull request
3. Documentar cambios claramente

## ğŸ“„ Licencia

Proyecto acadÃ©mico - UC3M 2025

## ğŸ‘¥ Autores

Proyecto Final - Procesamiento del Lenguaje Natural
MÃ¡ster en Inteligencia Artificial Aplicada
Universidad Carlos III de Madrid

## ğŸ”— Referencias

- [Proyecto RAG Original](https://arxiv.org/abs/2005.11401)
- [LangChain Documentation](https://python.langchain.com/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Ollama](https://ollama.ai/)

## â“ FAQ

### Â¿Por quÃ© el sistema dice "NO SE PUEDE VERIFICAR"?

- No hay documentos relevantes en la base de datos
- La afirmaciÃ³n es demasiado vaga o ambigua
- El tema no estÃ¡ cubierto en el corpus

**SoluciÃ³n**: AÃ±ade mÃ¡s documentos relacionados con el tema

### Â¿CÃ³mo mejoro la precisiÃ³n?

1. Aumentar el corpus documental
2. Ajustar parÃ¡metros de chunking
3. Aumentar `k` en bÃºsqueda vectorial
4. Usar un modelo de embeddings mÃ¡s potente
5. Optimizar los prompts

### Â¿Funciona sin conexiÃ³n a internet?

SÃ­, excepto para:
- Descargar modelos inicialmente
- TraducciÃ³n (usa Google Translator)
- Descargar artÃ­culos de Wikipedia

Para uso offline completo, considera usar modelos de traducciÃ³n locales.

### Â¿Puedo usar otros LLMs?

SÃ­, edita `config.yaml` y cambia el modelo. Opciones:

- Ollama: llama3.1, qwen3, gemma3
- OpenAI: gpt-4, gpt-3.5-turbo (requiere API key)
- HuggingFace: cualquier modelo compatible

---

**Â¿Preguntas?** Consulta la documentaciÃ³n completa o abre un issue.
