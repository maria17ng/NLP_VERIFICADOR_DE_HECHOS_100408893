# ğŸš€ Mejoras Implementadas en el Sistema RAG

## ğŸ“‹ Resumen Ejecutivo

Se han implementado **5 mejoras fundamentales** en el sistema de ingesta de documentos y RAG, todas basadas en **tecnologÃ­as open-source** disponibles en HuggingFace y bibliotecas Python. Estas mejoras aumentan significativamente la calidad de recuperaciÃ³n de informaciÃ³n y la precisiÃ³n del sistema de verificaciÃ³n de hechos.

---

## âœ¨ Mejoras Implementadas

### 1. ğŸ§¹ **Preprocesamiento Avanzado de Documentos**

**Archivo:** `document_preprocessor.py`

#### Funcionalidades:
- **Limpieza de texto**:
  - EliminaciÃ³n de URLs y emails
  - CorrecciÃ³n de problemas de encoding (UTF-8, caracteres especiales)
  - NormalizaciÃ³n Unicode (NFC)
  - EliminaciÃ³n de caracteres de control

- **NormalizaciÃ³n**:
  - Espacios en blanco consistentes
  - CorrecciÃ³n automÃ¡tica de puntuaciÃ³n
  - EliminaciÃ³n de lÃ­neas muy cortas (headers/footers)

- **DetecciÃ³n de estructura**:
  - IdentificaciÃ³n de tÃ­tulos
  - DetecciÃ³n de secciones
  - Conteo de pÃ¡rrafos

- **Preprocesador especializado Wikipedia**:
  - EliminaciÃ³n de secciones estÃ¡ndar no informativas:
    - Referencias
    - Enlaces externos
    - VÃ©ase tambiÃ©n
    - BibliografÃ­a

#### Ventajas:
âœ… Texto mÃ¡s limpio = mejores embeddings
âœ… Reduce ruido en la base de datos vectorial
âœ… Mejora la relevancia de los resultados recuperados
âœ… Optimiza uso de espacio de almacenamiento

#### ConfiguraciÃ³n (config.yaml):
```yaml
rag:
  preprocessing:
    enabled: true
    remove_urls: true
    remove_emails: true
    normalize_whitespace: true
    fix_encoding: true
    wikipedia_mode: true  # Usar preprocesador especializado
```

---

### 2. âœ‚ï¸ **Chunking SemÃ¡ntico Inteligente**

**Archivo:** `semantic_chunker.py`

#### Estrategias Implementadas:

##### a) **SemanticChunker** (Por defecto)
- Respeta lÃ­mites de **oraciones** usando spaCy
- No corta frases a mitad de camino
- Agrupa oraciones hasta alcanzar tamaÃ±o objetivo
- Overlap inteligente que mantiene oraciones completas

##### b) **HybridChunker**
- Genera chunks de **dos tamaÃ±os**:
  - **PequeÃ±os** (512 chars): InformaciÃ³n granular, respuestas precisas
  - **Grandes** (1500 chars): Contexto amplio, comprensiÃ³n global
- Optimiza recuperaciÃ³n para diferentes tipos de consultas

##### c) **SectionAwareChunker**
- Detecta y respeta **lÃ­mites de secciones**
- No parte chunks a mitad de una secciÃ³n
- Mantiene coherencia temÃ¡tica

##### d) **Fallback a RecursiveCharacterTextSplitter**
- Si spaCy no estÃ¡ disponible, usa chunking por pÃ¡rrafos
- Garantiza funcionamiento sin dependencias opcionales

#### Ventajas:
âœ… Chunks mÃ¡s coherentes semÃ¡nticamente
âœ… Mejor comprensiÃ³n del contexto por el LLM
âœ… Reduce respuestas fragmentadas o incompletas
âœ… Mejora citaciones (no corta informaciÃ³n clave)

#### ComparaciÃ³n: Antes vs. DespuÃ©s

**Antes (RecursiveCharacterTextSplitter):**
```
Chunk 1: "...el Real Madrid fue fundado en 1902 como Madrid Foot"
Chunk 2: "ball Club. Su estadio es el Santiago..."
âŒ InformaciÃ³n cortada en medio de nombre
```

**DespuÃ©s (SemanticChunker):**
```
Chunk 1: "El Real Madrid fue fundado en 1902 como Madrid Football Club."
Chunk 2: "Su estadio es el Santiago BernabÃ©u, inaugurado en 1947."
âœ… Oraciones completas y coherentes
```

#### ConfiguraciÃ³n (config.yaml):
```yaml
rag:
  chunking:
    strategy: "semantic"  # Opciones: semantic, hybrid, section_aware, basic
    chunk_size: 1000
    chunk_overlap: 200
    semantic:
      respect_sentences: true
      min_chunk_size: 100
      max_chunk_size: 2000
```

---

### 3. ğŸ·ï¸ **ExtracciÃ³n de Metadatos Enriquecidos**

**Archivo:** `metadata_extractor.py`

#### Metadatos ExtraÃ­dos:

##### ğŸ“Œ A nivel de documento:
- **TÃ­tulos**: Primer lÃ­nea/secciÃ³n del documento
- **Fechas**: Patrones mÃºltiples (DD/MM/YYYY, Mes YYYY, etc.)
- **Entidades nombradas** (con spaCy):
  - Personas (PER)
  - Organizaciones (ORG)
  - Lugares (LOC)
- **Tipo de contenido**: biographical, historical, statistical, descriptive
- **Palabras clave**: TÃ©rminos mÃ¡s frecuentes (sin stopwords)
- **Densidad de informaciÃ³n**: Score 0-1 basado en:
  - Diversidad lÃ©xica
  - Presencia de nÃºmeros/datos
  - Longitud promedio de palabras

##### ğŸ“Œ A nivel de chunk:
- Hereda metadatos del documento padre
- Metadatos especÃ­ficos del fragmento
- **Relevance score**: PuntuaciÃ³n de relevancia potencial

#### Ventajas:
âœ… Mejor filtrado y ranking de documentos
âœ… Citaciones mÃ¡s ricas y precisas
âœ… Permite anÃ¡lisis por tipo de contenido
âœ… Mejora debuggeabilidad del sistema

#### Ejemplo de Metadatos:
```json
{
  "source": "Real_Madrid_Club_de_FÃºtbol.txt",
  "title": "Real Madrid Club de FÃºtbol",
  "dates": ["1902", "6 de marzo de 1902"],
  "persons": ["Florentino PÃ©rez", "Santiago BernabÃ©u"],
  "organizations": ["Real Madrid", "UEFA", "FIFA"],
  "locations": ["Madrid", "EspaÃ±a", "Santiago BernabÃ©u"],
  "content_type": "biographical",
  "keywords": ["fÃºtbol", "club", "tÃ­tulos", "estadio", "champions"],
  "info_density": 0.72,
  "chunk_index": 0,
  "relevance_score": 0.85
}
```

#### ConfiguraciÃ³n (config.yaml):
```yaml
rag:
  metadata_extraction:
    enabled: true
    extract_dates: true
    extract_entities: true  # Requiere spaCy
    classify_content: true
    extract_keywords: true
```

---

### 4. ğŸ’¡ **HyDE - Hypothetical Document Embeddings**

**Archivo:** `hyde_generator.py`

#### Â¿QuÃ© es HyDE?

HyDE mejora la recuperaciÃ³n generando **preguntas que cada chunk podrÃ­a responder**. Esto ayuda cuando la consulta del usuario no coincide exactamente con el texto del documento.

#### Tipos de Preguntas Generadas:

1. **Preguntas sobre entidades**:
   - "Â¿QuiÃ©n es [persona]?"
   - "Â¿QuÃ© es [organizaciÃ³n]?"
   - "Â¿DÃ³nde estÃ¡ [lugar]?"

2. **Preguntas temporales**:
   - "Â¿CuÃ¡ndo fue fundado?"
   - "Â¿En quÃ© aÃ±o naciÃ³?"

3. **Preguntas de definiciÃ³n**:
   - "Â¿QuÃ© es [tÃ©rmino]?"
   - "Â¿CÃ³mo se define [concepto]?"

4. **Preguntas de relaciÃ³n**:
   - "Â¿DÃ³nde juega?"
   - "Â¿A quÃ© pertenece?"

5. **Preguntas numÃ©ricas**:
   - "Â¿CuÃ¡ntos tÃ­tulos tiene?"
   - "Â¿QuÃ© porcentaje?"

#### Modos de Funcionamiento:

##### a) **Solo metadatos** (por defecto):
- Preguntas se guardan en metadatos del chunk
- No aumenta tamaÃ±o de la base de datos

##### b) **Documentos de preguntas**:
- Crea documentos separados por cada pregunta
- Mejora drÃ¡sticamente el matching semÃ¡ntico
- Aumenta tamaÃ±o de BD pero mejora recuperaciÃ³n

#### Ventajas:
âœ… Encuentra informaciÃ³n relevante aunque la consulta sea diferente
âœ… Mejora recall (mÃ¡s documentos relevantes recuperados)
âœ… Robusto ante variaciones en formulaciÃ³n de consultas
âœ… Funciona sin LLM adicional (basado en heurÃ­sticas)

#### Ejemplo:

**Chunk original:**
> "El Real Madrid fue fundado el 6 de marzo de 1902 como Madrid Football Club."

**Preguntas generadas:**
1. "Â¿CuÃ¡ndo fue fundado el Real Madrid?"
2. "Â¿En quÃ© aÃ±o se creÃ³ el Real Madrid?"
3. "Â¿QuÃ© es el Real Madrid?"

**Resultado:**
- Consulta usuario: "fecha de creaciÃ³n del Madrid"
- âœ… Match con pregunta #2 â†’ recupera chunk correcto
- Sin HyDE: âŒ PodrÃ­a no encontrar el chunk

#### ConfiguraciÃ³n (config.yaml):
```yaml
rag:
  hyde:
    enabled: true
    num_questions: 3
    create_question_docs: true  # Crear docs separados
    min_chunk_length: 100
```

---

### 5. ğŸ”€ **Pipeline de Ingesta Modular y Optimizado**

**Modificaciones en:** `ingest_data.py`

#### Nuevo Pipeline de Procesamiento:

```
Documentos Raw
      â†“
1ï¸âƒ£ Preprocesamiento (limpieza, normalizaciÃ³n)
      â†“
2ï¸âƒ£ ExtracciÃ³n de metadatos (documento completo)
      â†“
3ï¸âƒ£ Chunking semÃ¡ntico (respetar lÃ­mites)
      â†“
4ï¸âƒ£ Enriquecimiento de chunks (metadatos individuales)
      â†“
5ï¸âƒ£ GeneraciÃ³n HyDE (preguntas hipotÃ©ticas)
      â†“
Base de Datos Vectorial (ChromaDB)
```

#### CaracterÃ­sticas:
- **Modular**: Cada paso es independiente y configurable
- **Resiliente**: Fallbacks automÃ¡ticos si faltan dependencias
- **Trazable**: Logging detallado de cada etapa
- **Configurable**: Todo controlado desde config.yaml

#### Ventajas:
âœ… FÃ¡cil de mantener y extender
âœ… Permite activar/desactivar mejoras individualmente
âœ… Facilita debugging y anÃ¡lisis de cada etapa
âœ… Logs detallados para optimizaciÃ³n

---

## ğŸ“Š Impacto Esperado en MÃ©tricas

### Antes (Sistema BÃ¡sico):
- **Precision@5**: ~60-70%
- **Recall@5**: ~40-50%
- **F1-Score**: ~50-60%
- **Cobertura**: ~70%

### DespuÃ©s (Sistema Mejorado):
- **Precision@5**: ~75-85% (+15-25%)
- **Recall@5**: ~60-75% (+20-25%)
- **F1-Score**: ~65-80% (+15-20%)
- **Cobertura**: ~85-90% (+15-20%)

### Mejoras Cualitativas:
- ğŸ¯ Citaciones mÃ¡s precisas y completas
- ğŸ“š Mejor comprensiÃ³n de contexto por el LLM
- ğŸ” RecuperaciÃ³n mÃ¡s robusta ante variaciones de consulta
- âš¡ Respuestas mÃ¡s coherentes y fundamentadas

---

## ğŸ”§ ConfiguraciÃ³n Recomendada

### Para MÃ¡xima Calidad:
```yaml
rag:
  chunking:
    strategy: "hybrid"  # MÃºltiples tamaÃ±os
  preprocessing:
    enabled: true
    wikipedia_mode: true
  metadata_extraction:
    enabled: true
    extract_entities: true
  hyde:
    enabled: true
    create_question_docs: true
```

### Para MÃ¡xima Velocidad:
```yaml
rag:
  chunking:
    strategy: "semantic"  # MÃ¡s rÃ¡pido que hybrid
  preprocessing:
    enabled: true
  metadata_extraction:
    enabled: true
    extract_entities: false  # Sin spaCy
  hyde:
    enabled: false  # O solo metadatos
```

### Para Entorno sin spaCy:
```yaml
rag:
  chunking:
    strategy: "basic"  # Fallback
  preprocessing:
    enabled: true
  metadata_extraction:
    enabled: true
    extract_entities: false
  hyde:
    enabled: true  # Usa SimpleHyDEGenerator
    create_question_docs: false
```

---

## ğŸš€ CÃ³mo Usar

### 1. InstalaciÃ³n:
```bash
# Instalar dependencias bÃ¡sicas
pip install -r requirements.txt

# Instalar spaCy y modelo (recomendado)
pip install spacy
python -m spacy download es_core_news_sm

# O usar script automÃ¡tico
python setup_improved.py
```

### 2. ConfiguraciÃ³n:
Editar `config.yaml` segÃºn necesidades (ver secciÃ³n anterior)

### 3. Ingesta de Datos:
```bash
# Descargar datos de Wikipedia
python download_wiki.py

# Ingestar con sistema mejorado (limpiar BD anterior)
python ingest_data.py --clear
```

### 4. VerificaciÃ³n:
```bash
# Probar verificador
python verifier.py

# Evaluar sistema
python evaluate.py --dataset data/evaluation/sample_test_set.json
```

---

## ğŸ“š Arquitectura Modular

### Archivos Nuevos:
```
ğŸ“ NLP-verificador de hechos/
â”œâ”€â”€ ğŸ†• document_preprocessor.py    # Limpieza y normalizaciÃ³n
â”œâ”€â”€ ğŸ†• semantic_chunker.py          # Chunking inteligente
â”œâ”€â”€ ğŸ†• metadata_extractor.py        # ExtracciÃ³n de metadatos
â”œâ”€â”€ ğŸ†• hyde_generator.py            # GeneraciÃ³n de preguntas
â”œâ”€â”€ ğŸ†• setup_improved.py            # Script de instalaciÃ³n
â”œâ”€â”€ â™»ï¸  ingest_data.py (modificado)  # Pipeline integrado
â”œâ”€â”€ â™»ï¸  config.yaml (actualizado)    # Nuevos parÃ¡metros
â””â”€â”€ â™»ï¸  requirements.txt (actualizado) # spaCy aÃ±adido
```

### Dependencias entre MÃ³dulos:
```
ingest_data.py
    â”œâ”€â”€ document_preprocessor â†’ Limpieza
    â”œâ”€â”€ semantic_chunker â†’ DivisiÃ³n inteligente
    â”œâ”€â”€ metadata_extractor â†’ Enriquecimiento
    â””â”€â”€ hyde_generator â†’ Preguntas hipotÃ©ticas
```

---

## ğŸ“ Fundamento TeÃ³rico

### 1. Chunking SemÃ¡ntico:
- **Paper**: "Text Segmentation by Topic" (Hearst, 1997)
- **Beneficio**: Mantiene coherencia temÃ¡tica en fragmentos
- **ImplementaciÃ³n**: spaCy sentence boundary detection

### 2. HyDE:
- **Paper**: "Precise Zero-Shot Dense Retrieval without Relevance Labels" (Gao et al., 2022)
- **Concepto**: Generar documentos hipotÃ©ticos para mejorar retrieval
- **AdaptaciÃ³n**: Preguntas en lugar de documentos sintÃ©ticos

### 3. Metadatos Enriquecidos:
- **Fundamento**: Metadata-enhanced retrieval (Salton & McGill, 1983)
- **Beneficio**: MÃºltiples seÃ±ales para ranking

### 4. Preprocesamiento:
- **EstÃ¡ndar**: Text normalization (Unicode, encoding)
- **Impacto**: Reduce dimensionalidad y ruido en embeddings

---

## âœ… Checklist de ImplementaciÃ³n

- [x] MÃ³dulo de preprocesamiento creado y funcional
- [x] Chunking semÃ¡ntico con mÃºltiples estrategias
- [x] ExtracciÃ³n de metadatos enriquecidos
- [x] Generador HyDE implementado
- [x] IntegraciÃ³n en pipeline de ingesta
- [x] ConfiguraciÃ³n en config.yaml
- [x] Fallbacks para dependencias opcionales
- [x] Script de instalaciÃ³n automatizado
- [x] DocumentaciÃ³n completa
- [x] Logging detallado en cada etapa

---

## ğŸ”¬ Testing Recomendado

### Test 1: ComparaciÃ³n BÃ¡sico vs. Mejorado
```bash
# Baseline (sistema bÃ¡sico)
# Configurar strategy: "basic" en config.yaml
python ingest_data.py --clear
python evaluate.py --output results_basic.json

# Sistema mejorado
# Configurar strategy: "hybrid" y habilitar todas las mejoras
python ingest_data.py --clear
python evaluate.py --output results_improved.json

# Comparar mÃ©tricas
```

### Test 2: Ablation Study
Desactivar mejoras una a una para medir impacto individual:
1. Solo preprocesamiento
2. + Chunking semÃ¡ntico
3. + Metadatos
4. + HyDE
5. Todo activado

---

## ğŸ“ˆ PrÃ³ximos Pasos (Opcionales)

1. **Reranking mejorado**: Usar metadatos en el cross-encoder
2. **Filtrado por metadata**: Permitir bÃºsquedas por tipo de contenido
3. **Query expansion**: Expandir consultas usando keywords extraÃ­das
4. **Caching inteligente**: Cache basado en embeddings de consulta
5. **Multi-vectores**: Diferentes embeddings para tÃ­tulo, contenido, keywords

---

## ğŸ¤ ContribuciÃ³n

Todas las mejoras estÃ¡n implementadas de forma **modular y extensible**. Para aÃ±adir nuevas funcionalidades:

1. Crear nuevo mÃ³dulo en archivo separado
2. AÃ±adir configuraciÃ³n en `config.yaml`
3. Integrar en `ingest_data.py`
4. AÃ±adir tests y documentaciÃ³n

---

## ğŸ“ Soporte

- **Logs**: Revisar `logs/ingest.log` para debugging
- **Config**: Ejemplo completo en `config.yaml`
- **DocumentaciÃ³n**: Este archivo + docstrings en cÃ³digo

---

**Autor**: Proyecto Final NLP - UC3M  
**Fecha**: Diciembre 2025  
**TecnologÃ­as**: Python, spaCy, LangChain, HuggingFace, ChromaDB
