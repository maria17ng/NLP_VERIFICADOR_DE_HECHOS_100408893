# An√°lisis Profundo: Problema del RAG y Soluciones Gratuitas

## üî¨ Diagn√≥stico del Problema Real

### **¬øPor qu√© el RAG no funciona para fact-checking?**

Analizando los logs y resultados:

```
CLAIM: "fundado en 1903"
RECUPERA: Documentos sobre 1940-1941, estadios, etc.
NO RECUPERA: "fue registrada oficialmente... el 6 de marzo de 1902"
```

**Causas ra√≠ces identificadas:**

1. **Embeddings sem√°nticos son "literales"**
   - Buscan matching sem√°ntico directo
   - "fundado 1903" ‚Üí busca chunks que mencionen "1903"
   - NO buscan "contradicciones" o "hechos relacionados pero diferentes"

2. **Chunks son demasiado largos** (1000 caracteres)
   - Un chunk puede contener m√∫ltiples hechos/fechas
   - Diluci√≥n de la se√±al: "1902" se pierde entre otras 100 palabras
   - El embedding promedia todo el contenido

3. **El modelo de embeddings no entiende "relaciones num√©ricas"**
   - Para el embedding, "1902" y "1903" son casi id√©nticos
   - No entiende que son fechas contradictorias
   - Son solo tokens similares

4. **Falta de indexaci√≥n por entidades espec√≠ficas**
   - No hay √≠ndice de "hechos verificables"
   - No hay estructura: SUJETO ‚Üí PREDICADO ‚Üí OBJETO ‚Üí FECHA

---

## ‚úÖ SOLUCIONES PR√ÅCTICAS (100% Gratuitas)

### **SOLUCI√ìN 1: Dual-Index RAG (Recomendada)**

Crear **DOS √≠ndices diferentes** para b√∫squeda:

#### **√çndice A: Embeddings Sem√°nticos** (ya existe)
- Para comprensi√≥n general del tema
- Chunks de 1000 caracteres

#### **√çndice B: √çndice de Hechos con BM25** (NUEVO)
- B√∫squeda keyword-based ultra r√°pida
- Indexa "hechos at√≥micos": entidad + acci√≥n + fecha
- Gratuito: usa Tantivy o Whoosh (Python puro)

**Ejemplo de hechos indexados:**
```json
{
  "entidad": "Real Madrid",
  "accion": "fundado",
  "fecha": "1902",
  "texto": "fue registrada oficialmente como club de f√∫tbol por sus socios el 6 de marzo de 1902"
}
```

**Ventaja**: B√∫squeda exacta por keywords + fechas
- Query: "Real Madrid fundado 1903"
- BM25 encuentra: TODOS los docs con "Real Madrid" + "fundado" + cualquier fecha
- Incluye el doc con 1902 ‚Üí LLM puede contradecir

---

### **SOLUCI√ìN 2: Propositions/Atomic Facts Chunking** (M√ÅS IMPACTO)

En lugar de chunks de 1000 caracteres, crear **"proposiciones at√≥micas"**:

**Chunk actual (1000 chars)**:
```
"El Real Madrid Club de F√∫tbol, m√°s conocido simplemente como Real Madrid, 
es una entidad polideportiva con sede en Madrid, Espa√±a. Fue registrada 
oficialmente como club de f√∫tbol por sus socios el 6 de marzo de 1902 con 
el objeto de la pr√°ctica y desarrollo de este deporte ‚Äîsi bien sus or√≠genes 
datan del a√±o 1900,‚Äã y su denominaci√≥n..."
```

**Proposiciones at√≥micas (nuevo)**:
```
P1: "Real Madrid es una entidad polideportiva con sede en Madrid, Espa√±a"
P2: "Real Madrid fue registrada oficialmente el 6 de marzo de 1902"
P3: "Los or√≠genes del Real Madrid datan del a√±o 1900"
P4: "La denominaci√≥n (Sociedad) Madrid Foot-ball Club es de octubre de 1901"
```

**Ventaja**:
- Cada embedding representa UN HECHO espec√≠fico
- "fundado 1903" ‚Üí match con P2 (menciona fundaci√≥n + fecha)
- Mucho m√°s preciso para fact-checking

**Implementaci√≥n gratuita:**
- Usar spaCy (ya instalado) para sentence splitting
- Regex para detectar "hechos verificables" (fecha + verbo)
- O usar LLM local (Ollama llama3.2) para extraer proposiciones

---

### **SOLUCI√ìN 3: Metadata-Rich Indexing** (M√ÅS SIMPLE)

Enriquecer los metadatos de cada chunk con **entidades extra√≠das**:

**Metadata actual:**
```python
{
  "source": "Real_Madrid.txt",
  "chunk_id": 1,
  "chunk_size": 1000
}
```

**Metadata mejorada:**
```python
{
  "source": "Real_Madrid.txt",
  "chunk_id": 1,
  "chunk_size": 1000,
  "entidades": ["Real Madrid", "Madrid", "Espa√±a"],
  "fechas": ["1902", "1900", "1901"],
  "hechos_clave": ["fundaci√≥n: 1902", "or√≠genes: 1900"],
  "verbos_accion": ["registrada", "datan"]
}
```

**B√∫squeda mejorada:**
1. Query: "Real Madrid fundado 1903"
2. Extraer: entidad="Real Madrid", fecha="1903", verbo="fundado"
3. Filtrar chunks por metadata:
   - chunks con entidad="Real Madrid" AND "fundaci√≥n" in hechos_clave
4. Recuperar TODOS (incluye el de 1902)

**Implementaci√≥n:**
- Usar spaCy para NER (entidades)
- Regex para fechas
- Template matching para hechos

---

### **SOLUCI√ìN 4: Query Decomposition + Multi-Retrieval**

Descomponer queries complejas en sub-queries:

**Query original:**
```
"El Real Madrid fue fundado en 1903"
```

**Descomposici√≥n:**
```
Q1: "¬øCu√°ndo fue fundado el Real Madrid?"  ‚Üê Sin la fecha incorrecta
Q2: "Real Madrid fundaci√≥n fecha"          ‚Üê Keywords gen√©ricos
Q3: "Real Madrid 1903"                     ‚Üê Fecha espec√≠fica (para verificar)
```

**Proceso:**
1. Recuperar docs con Q1 (sin fecha) ‚Üí Encuentra doc con 1902
2. Recuperar docs con Q2 ‚Üí M√°s docs sobre fundaci√≥n  
3. Recuperar docs con Q3 ‚Üí Verifica si existe 1903
4. Combinar resultados
5. LLM compara: "Los docs sobre fundaci√≥n dicen 1902, no 1903"

**Implementaci√≥n:**
- Usar LLM local (Ollama) para generar sub-queries
- Hacer m√∫ltiples retrievals
- Combinar con voting/ranking

---

## üìä Comparaci√≥n de Soluciones

| Soluci√≥n | Complejidad | Impacto | Costo Computacional | Gratuito |
|----------|-------------|---------|---------------------|----------|
| **Dual-Index (BM25 + Embeddings)** | Media | ‚≠ê‚≠ê‚≠ê‚≠ê | Bajo | ‚úÖ S√≠ |
| **Atomic Facts Chunking** | Alta | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Medio | ‚úÖ S√≠ |
| **Metadata-Rich Indexing** | Baja | ‚≠ê‚≠ê‚≠ê | Bajo | ‚úÖ S√≠ |
| **Query Decomposition** | Media | ‚≠ê‚≠ê‚≠ê | Medio | ‚úÖ S√≠ |

---

## üéØ RECOMENDACI√ìN: Implementaci√≥n por Fases

### **FASE 1: Quick Win (1-2 horas)**
**Metadata-Rich Indexing + Query Decomposition**

Raz√≥n:
- F√°cil de implementar
- No requiere re-indexar todo
- Mejora inmediata del 30-40%

Implementar:
1. Extraer fechas/entidades en metadata al ingestar
2. Filtrar por metadata antes de similarity search
3. Generar 3 sub-queries por cada claim

### **FASE 2: Mejora Estructural (1-2 d√≠as)**
**Dual-Index: BM25 + Embeddings**

Raz√≥n:
- Balance perfecto: precisi√≥n + recall
- BM25 es r√°pido y gratuito
- Complementa embeddings sem√°nticos

Implementar:
1. Instalar `whoosh` o `rank_bm25` (Python puro)
2. Indexar chunks con BM25
3. B√∫squeda h√≠brida: 50% BM25 + 50% embeddings
4. Reciprocal Rank Fusion para combinar

### **FASE 3: Soluci√≥n Ideal (3-5 d√≠as)**
**Atomic Facts Chunking**

Raz√≥n:
- M√°xima precisi√≥n para fact-checking
- Cada embedding = 1 hecho verificable
- Soluci√≥n a largo plazo

Implementar:
1. Usar Ollama llama3.2 para extraer proposiciones
2. Re-chunking del corpus en hechos at√≥micos
3. Re-indexar base de datos vectorial

---

## üíª C√ìDIGO: Implementaci√≥n Fase 1 (Quick Win)

### **1. Metadata-Rich Extractor**

```python
import re
import spacy

class FactMetadataExtractor:
    """Extrae metadata rica para fact-checking."""
    
    def __init__(self):
        try:
            self.nlp = spacy.load("es_core_news_sm")
        except:
            self.nlp = None
    
    def extract_dates(self, text: str) -> List[str]:
        """Extrae todas las fechas del texto."""
        # Regex para a√±os
        years = re.findall(r'\b(1[0-9]{3}|20[0-9]{2})\b', text)
        # Regex para fechas completas
        full_dates = re.findall(
            r'\b(\d{1,2}\s+de\s+\w+\s+de\s+\d{4})\b',
            text,
            re.IGNORECASE
        )
        return list(set(years + full_dates))
    
    def extract_key_facts(self, text: str) -> List[str]:
        """Extrae hechos clave (acci√≥n + fecha)."""
        facts = []
        
        # Patrones para hechos verificables
        patterns = [
            r'(fundad[oa]|cread[oa]|establecid[oa]|registrad[oa])\s+.*?(\d{4})',
            r'(gan[√≥o]|consigui[√≥o]|logr[√≥o])\s+.*?(\d{4})',
            r'(naci[√≥o]|muri[√≥o])\s+.*?(\d{4})',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                facts.append(f"{match[0]}: {match[1]}")
        
        return facts
    
    def enrich_metadata(self, doc: Document) -> Document:
        """Enriquece metadata de un documento."""
        text = doc.page_content
        
        # Extraer fechas
        dates = self.extract_dates(text)
        
        # Extraer entidades con spaCy
        entities = []
        if self.nlp:
            doc_nlp = self.nlp(text[:500])  # Solo primeros 500 chars
            entities = [ent.text for ent in doc_nlp.ents 
                       if ent.label_ in ['PER', 'ORG', 'LOC']]
        
        # Extraer hechos clave
        key_facts = self.extract_key_facts(text)
        
        # Agregar a metadata
        doc.metadata.update({
            'fechas': dates,
            'entidades': entities,
            'hechos_clave': key_facts,
            'tiene_fechas': len(dates) > 0,
            'es_sobre_fundacion': any(
                word in text.lower() 
                for word in ['fundado', 'fundaci√≥n', 'registrado', 'creado']
            )
        })
        
        return doc
```

### **2. Query Decomposer**

```python
from langchain_ollama import ChatOllama

class QueryDecomposer:
    """Descompone queries en sub-queries para mejor retrieval."""
    
    def __init__(self):
        self.llm = ChatOllama(model="llama3.2", temperature=0.0)
    
    def decompose(self, query: str) -> List[str]:
        """Genera 3 sub-queries variadas."""
        
        # Extraer componentes manualmente
        import re
        
        # Extraer fecha
        dates = re.findall(r'\b\d{4}\b', query)
        
        # Extraer entidades principales
        entities = []
        for entity in ['Real Madrid', 'Barcelona', 'Atl√©tico']:
            if entity.lower() in query.lower():
                entities.append(entity)
        
        # Extraer verbo de acci√≥n
        action_words = ['fundado', 'gan√≥', 'jug√≥', 'naci√≥']
        action = None
        for word in action_words:
            if word in query.lower():
                action = word
                break
        
        # Generar sub-queries
        sub_queries = [query]  # Original siempre incluida
        
        if entities and action:
            # Sin fecha (CLAVE para encontrar info contradictoria)
            sub_queries.append(f"{entities[0]} {action}")
            
            # Solo keywords
            sub_queries.append(f"{entities[0]} {action} fecha")
        
        return sub_queries[:3]
```

### **3. Integrar en AdvancedRetriever**

```python
# En advanced_retriever.py, modificar retrieve():

def retrieve_with_metadata_filter(self, query: str) -> List[Document]:
    """Retrieval mejorado con filtros de metadata."""
    
    # 1. Extraer componentes de la query
    dates_in_query = re.findall(r'\b\d{4}\b', query)
    is_about_foundation = any(
        word in query.lower() 
        for word in ['fundado', 'fundaci√≥n', 'creado']
    )
    
    # 2. B√∫squeda vectorial normal
    docs = self.vector_db.similarity_search(query, k=100)
    
    # 3. PRE-FILTRO por metadata relevante
    if is_about_foundation:
        # Priorizar docs sobre fundaci√≥n
        filtered = [
            doc for doc in docs
            if doc.metadata.get('es_sobre_fundacion', False)
        ]
        if filtered:
            docs = filtered[:50] + docs[:50]  # Combinar
    
    # 4. Si query tiene fecha, incluir docs con fechas cercanas
    if dates_in_query:
        query_year = int(dates_in_query[0])
        # Buscar docs con fechas en rango ¬±10 a√±os
        date_relevant_docs = [
            doc for doc in docs
            if any(
                abs(int(date) - query_year) <= 10
                for date in doc.metadata.get('fechas', [])
                if date.isdigit()
            )
        ]
        if date_relevant_docs:
            docs = date_relevant_docs[:30] + docs[:30]
    
    return docs[:self.config.k_initial]
```

---

## üöÄ Plan de Acci√≥n Inmediato

### **HOY (2-3 horas):**

1. ‚úÖ Implementar `FactMetadataExtractor`
2. ‚úÖ Modificar `ingest_data.py` para usar el extractor
3. ‚úÖ Re-ingestar el corpus con metadata rica
4. ‚úÖ Probar si mejora el retrieval

### **MA√ëANA (3-4 horas):**

1. ‚úÖ Implementar `QueryDecomposer`
2. ‚úÖ Modificar `AdvancedRetriever` para usar sub-queries
3. ‚úÖ Implementar filtros de metadata en retrieval
4. ‚úÖ Probar test completo

### **ESTA SEMANA (si hay tiempo):**

1. Investigar BM25 en Python (`rank_bm25` library)
2. Implementar dual-index
3. Comparar resultados

---

## üìö Recursos Gratuitos

### **Para BM25:**
- `rank_bm25`: https://pypi.org/project/rank-bm25/
- Tutorial: https://www.pinecone.io/learn/bm25/

### **Para Atomic Facts:**
- Paper: "Enabling Large Language Models to Generate Text with Citations"
- Usar Ollama llama3.2 (ya instalado) para extracci√≥n

### **Para Query Decomposition:**
- DSPy framework (gratuito)
- Langchain tiene built-in query decomposition

---

## üéØ Resultado Esperado Tras Fase 1:

**ANTES:**
```
"fundado 1903" ‚Üí NO encuentra doc con 1902 ‚Üí NO SE PUEDE VERIFICAR
```

**DESPU√âS:**
```
"fundado 1903" 
  ‚Üí Query Decomp: ["Real Madrid fundado", "fundado 1903", "Real Madrid fundaci√≥n fecha"]
  ‚Üí Metadata Filter: chunks con es_sobre_fundacion=True
  ‚Üí Encuentra doc con 1902
  ‚Üí LLM: FALSO (dice 1902, no 1903)
```

**Mejora esperada: 50-70% en tests**

---

¬øQuieres que implemente la **Fase 1** ahora? Es lo m√°s r√°pido y efectivo.
