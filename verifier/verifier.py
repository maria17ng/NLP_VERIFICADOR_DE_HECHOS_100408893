import time
import os
import hashlib
import random
from collections import Counter
import numpy as np
from typing import Dict, List, Any, Optional, Tuple

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import ChatOllama
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from sentence_transformers import CrossEncoder

# Importaciones locales
from language import ProcesadorMultilingue
from utils.utils import ConfigManager, setup_logger, load_prompts
from retriever import AdvancedRetriever, RetrievalConfig
from summarizer import EvidenceSummarizer

from pathlib import Path
from dotenv import load_dotenv
dotenv_path = Path('settings/.env')
load_dotenv(dotenv_path=dotenv_path)


class FactChecker:
    """
    Verificador de hechos basado en RAG con soporte multiling√ºe.

    Esta clase implementa un sistema completo de verificaci√≥n que:
    1. Detecta el idioma de entrada y traduce si es necesario
    2. Recupera evidencia relevante de una base de datos vectorial
    3. Usa un LLM para determinar la veracidad
    4. Retorna respuestas en el idioma original del usuario
    5. Mantiene cach√© de consultas para optimizaci√≥n

    Attributes:
        config: Gestor de configuraci√≥n del sistema
        logger: Logger para registro de eventos
        prompts: Plantillas de prompts para el LLM
        linguist: Procesador multiling√ºe para traducci√≥n
        cache: Diccionario para almacenar consultas previas
        embeddings: Modelo de embeddings para b√∫squeda sem√°ntica
        vector_db: Base de datos vectorial (ChromaDB)
        reranker: Modelo de reranking para mejorar recuperaci√≥n
        advanced_retriever: Pipeline avanzado de recuperaci√≥n
        llm: Modelo de lenguaje para generaci√≥n
        chain: Cadena de procesamiento LangChain
    """

    SUPPORTED_TEAM_KEYWORDS = {
        "real_madrid": {
            "display": "Real Madrid",
            "keywords": (
                "real madrid",
                "real madrid club de f√∫tbol",
                "real madrid club de futbol",
                "madridista",
                "madridistas",
                "merengue",
                "merengues",
                "santiago bernab√©u",
                "santiago bernabeu",
                "bernab√©u",
                "bernabeu"
            )
        },
        "atletico_madrid": {
            "display": "Atl√©tico de Madrid",
            "keywords": (
                "atl√©tico de madrid",
                "atletico de madrid",
                "atl√©tico",
                "atletico",
                "atleti",
                "colchonero",
                "colchoneros",
                "rojiblanco",
                "rojiblancos",
                "c√≠vitas metropolitano",
                "civitas metropolitano",
                "wanda metropolitano",
                "metropolitano"
            )
        },
        "getafe": {
            "display": "Getafe CF",
            "keywords": (
                "getafe",
                "getafe cf",
                "getafe club de f√∫tbol",
                "getafe club de futbol",
                "azul√≥n",
                "azulon",
                "azulones",
                "coliseum alfonso p√©rez",
                "coliseum alfonso perez",
                "alfonso p√©rez",
                "alfonso perez"
            )
        },
        "leganes": {
            "display": "CD Legan√©s",
            "keywords": (
                "legan√©s",
                "leganes",
                "club deportivo legan√©s",
                "club deportivo leganes",
                "cd legan√©s",
                "cd leganes",
                "pepineros",
                "pepineras",
                "butarque"
            )
        },
        "rayo_vallecano": {
            "display": "Rayo Vallecano",
            "keywords": (
                "rayo vallecano",
                "rayo",
                "vallecano",
                "rayista",
                "rayistas",
                "vallecas",
                "franja roja"
            )
        }
    }

    def __init__(self, config_path: str = "config.yaml"):
        """
        Inicializa el sistema de verificaci√≥n de hechos.

        Args:
            config_path: Ruta al archivo de configuraci√≥n YAML

        Raises:
            FileNotFoundError: Si no se encuentran archivos de configuraci√≥n
            Exception: Si falla la carga de modelos
        """
        # Configuraci√≥n y logging
        self.config = ConfigManager(config_path)
        self.logger = setup_logger(
            name="FactChecker",
            level=self.config.get('logging.level', 'INFO'),
            log_file=os.path.join(
                self.config.get_path('logs'),
                'fact_checker.log'
            ),
            console=self.config.get('logging.console_enabled', True)
        )

        self.logger.info("=" * 70)
        self.logger.info("Iniciando Sistema de Verificaci√≥n de Hechos")
        self.logger.info("=" * 70)

        # Cargar prompts
        self._load_prompts()

        # Forzar modo determinista si est√° configurado
        self._configure_determinism()

        # Inicializar componentes
        self._init_language_processor()
        self._init_cache()
        self._init_embeddings()
        self._init_vector_db()
        self._init_reranker()
        self._init_advanced_retriever()
        self._init_llm()
        self._init_summarizer()

        self.logger.info("‚úÖ Sistema inicializado correctamente")
        self.logger.info("=" * 70)

    def _load_prompts(self) -> None:
        """Carga las plantillas de prompts desde archivo YAML."""
        try:
            prompts_path = self.config.get_path('prompts')
            self.prompts = load_prompts(prompts_path)
            self.logger.info(f"Prompts cargados desde: {prompts_path}")
        except FileNotFoundError as e:
            self.logger.error(f"‚ùå Error cargando prompts: {e}")
            raise

    def _configure_determinism(self) -> None:
        """Configura semillas globales para reducir la aleatoriedad."""
        if not self.config.get('deterministic_mode.enabled', False):
            return

        seed = int(self.config.get('deterministic_mode.seed', 42))
        random.seed(seed)
        np.random.seed(seed)

        try:
            import torch  # type: ignore
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed_all(seed)
        except Exception:
            # Torch puede no estar disponible en todos los entornos; continuar silenciosamente
            pass

        self.logger.info(f"üîí Modo determinista activado (seed={seed})")

    def _init_language_processor(self) -> None:
        """Inicializa el procesador multiling√ºe."""
        try:
            lid_model_path = self.config.get_path('lid_model')
            self.linguist = ProcesadorMultilingue(model_path=lid_model_path)
            self.logger.info("Procesador multiling√ºe inicializado")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è  Error inicializando procesador de idiomas: {e}")
            self.linguist = None

    def _init_cache(self) -> None:
        """Inicializa el sistema de cach√©."""
        if self.config.get('cache.enabled', True):
            self.cache = {}
            self.cache_max_size = self.config.get('cache.max_size', 1000)
            self.logger.info(f"Cach√© habilitado (tama√±o m√°x: {self.cache_max_size})")
        else:
            self.cache = None
            self.logger.info("Cach√© deshabilitado")

    def _init_embeddings(self) -> None:
        """Inicializa el modelo de embeddings."""
        try:
            # Verificar si usar OpenAI o HuggingFace
            provider = self.config.get('models.embeddings.provider', 'huggingface')

            if provider == 'openai':
                # Usar OpenAI embeddings
                api_key = self.config.get('models.openai.api_key') or os.getenv('OPENAI_KEY')
                if not api_key:
                    self.logger.warning("‚ö†Ô∏è  OpenAI API key no encontrada, usando HuggingFace como fallback")
                    provider = 'huggingface'
                else:
                    model_name = self.config.get('models.embeddings.openai_model', 'text-embedding-3-small')
                    self.logger.info(f"Cargando OpenAI embeddings: {model_name}")
                    self.embeddings = OpenAIEmbeddings(
                        model=model_name,
                        openai_api_key=api_key
                    )
                    self.logger.info(f"‚úÖ Embeddings cargados: OpenAI {model_name}")
                    return

            # Fallback o default: HuggingFace
            if provider == 'huggingface':
                model_name = self.config.get('models.embeddings.name')
                self.embeddings = HuggingFaceEmbeddings(model_name=model_name)
                self.logger.info(f"Embeddings cargados: {model_name}")
        except Exception as e:
            self.logger.error(f"‚ùå Error cargando embeddings: {e}")
            raise

    def _init_vector_db(self) -> None:
        """Inicializa la conexi√≥n a la base de datos vectorial."""
        try:
            db_path = self.config.get_path('vector_store')

            if os.path.exists(db_path):
                self.vector_db = Chroma(
                    persist_directory=db_path,
                    embedding_function=self.embeddings
                )
                # Obtener n√∫mero de documentos
                collection = self.vector_db._collection
                doc_count = collection.count()
                self.logger.info(f"‚úÖ Base de datos vectorial conectada: {db_path}")
                self.logger.info(f"\tDocumentos en BD: {doc_count}")
            else:
                self.vector_db = None
                self.logger.warning(f"‚ö†Ô∏è  No se encontr√≥ la base de datos vectorial en: {db_path}")
                self.logger.warning("   Por favor, ejecuta ingest_data.py primero")

        except Exception as e:
            self.logger.error(f"‚ùå Error conectando a la base de datos: {e}")
            self.vector_db = None

    def _init_reranker(self) -> None:
        """Inicializa el modelo de reranking."""
        try:
            model_name = self.config.get('models.reranker.name')
            self.reranker = CrossEncoder(model_name)
            self.logger.info(f"Reranker cargado: {model_name}")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è  Error cargando reranker: {e}")
            self.reranker = None

    def _init_advanced_retriever(self) -> None:
        """Inicializa el pipeline avanzado de recuperaci√≥n."""
        if not self.vector_db:
            self.logger.warning("‚ö†Ô∏è  No se puede inicializar AdvancedRetriever sin vector_db")
            self.advanced_retriever = None
            return

        try:
            # Configuraci√≥n del retriever desde config.yaml
            rag_config = self.config.get_rag_config()

            retrieval_config = RetrievalConfig(
                k_initial=rag_config.get('similarity_search', {}).get('k', 50),
                use_metadata_filter=rag_config.get('advanced_retrieval', {}).get('use_metadata_filter', True),
                metadata_boost=rag_config.get('advanced_retrieval', {}).get('metadata_boost', 0.2),
                use_hybrid_search=rag_config.get('advanced_retrieval', {}).get('use_hybrid_search', True),
                keyword_weight=rag_config.get('advanced_retrieval', {}).get('keyword_weight', 0.3),
                use_reranker=self.reranker is not None,
                rerank_top_k=rag_config.get('advanced_retrieval', {}).get('rerank_top_k', 20),
                use_diversity=rag_config.get('advanced_retrieval', {}).get('use_diversity', True),
                max_chunks_per_source=rag_config.get('advanced_retrieval', {}).get('max_chunks_per_source', 3),
                diversity_penalty=rag_config.get('advanced_retrieval', {}).get('diversity_penalty', 0.1),
                min_relevance_score=rag_config.get('advanced_retrieval', {}).get('min_relevance_score', 0.3),
                min_rerank_score=rag_config.get('advanced_retrieval', {}).get('min_rerank_score', -5.0),
                final_top_k=rag_config.get('reranking', {}).get('top_k', 5)
            )

            self.advanced_retriever = AdvancedRetriever(
                vector_db=self.vector_db,
                reranker=self.reranker,
                config=retrieval_config
            )

            self.logger.info("Pipeline avanzado de recuperaci√≥n inicializado")

        except Exception as e:
            self.logger.error(f"‚ùå Error inicializando AdvancedRetriever: {e}")
            self.advanced_retriever = None

    def _init_llm(self) -> None:
        """Inicializa el modelo de lenguaje (OpenAI u Ollama) y la cadena de procesamiento."""
        # Inicializar atributos por defecto
        self.llm = None
        self.chain = None

        try:
            llm_config = self.config.get_model_config('llm')
            openai_config = self.config.config.get('models', {}).get('openai', {})
            deterministic_mode = self.config.get('deterministic_mode.enabled', False)

            # Selector: OpenAI si est√° habilitado, sino Ollama
            if openai_config.get('enabled', False):
                # OpenAI
                api_key = openai_config.get('api_key') or os.getenv('OPENAI_KEY')
                if not api_key:
                    raise ValueError(
                        "OpenAI enabled pero no se encontr√≥ api_key. "
                        "A√±ade api_key en config.yaml o variable OPENAI_KEY."
                    )

                base_temperature = openai_config.get('temperature', 0.1)
                temperature = 0.0 if deterministic_mode else base_temperature
                top_p = openai_config.get('top_p', 1.0)
                top_p = max(min(top_p, 1.0), 1e-5)

                self.llm = ChatOpenAI(
                    model=openai_config.get('model', 'gpt-4o-mini'),
                    temperature=temperature,
                    top_p=top_p,
                    max_tokens=openai_config.get('max_tokens', 800),
                    api_key=api_key
                )
                self.logger.info(f"LLM inicializado: OpenAI {openai_config.get('model', 'gpt-4o-mini')}")
                self.logger.info(
                    f"  Temperatura: {temperature}{' (determinista)' if deterministic_mode else ''}"
                )
            else:
                # Ollama (comportamiento original)
                llm_params = {
                    'model': llm_config.get('name', 'llama3.2'),
                    'temperature': 0.0 if deterministic_mode else llm_config.get('temperature', 0.1),
                    'format': llm_config.get('format', 'json'),
                    'keep_alive': llm_config.get('keep_alive', '5m')
                }

                # Si hay URL base y API key (para UC3M)
                if 'base_url' in llm_config:
                    llm_params['base_url'] = llm_config['base_url']
                if 'api_key' in llm_config:
                    llm_params['api_key'] = llm_config['api_key']

                self.llm = ChatOllama(**llm_params)
                self.logger.info(f"LLM inicializado: Ollama {llm_params['model']}")
                self.logger.info(
                    f"  Temperatura: {llm_params['temperature']}{' (determinista)' if deterministic_mode else ''}"
                )

            # Verificar que LLM se inicializ√≥
            if self.llm is None:
                raise RuntimeError("El LLM no se inicializ√≥ correctamente")

            # Inicializar cadena
            self.logger.info("Creando cadena de procesamiento...")

            if 'verification_prompt' not in self.prompts:
                raise KeyError("No se encontr√≥ 'verification_prompt' en los prompts cargados")

            prompt_template = ChatPromptTemplate.from_template(
                self.prompts['verification_prompt']
            )
            self.chain = prompt_template | self.llm | JsonOutputParser()

            # Verificar que la cadena se cre√≥
            if self.chain is None:
                raise RuntimeError("La cadena de procesamiento no se inicializ√≥ correctamente")

            self.logger.info("‚úÖ Cadena de procesamiento inicializada correctamente")

        except Exception as e:
            self.logger.error(f"‚ùå Error inicializando LLM: {e}")
            import traceback
            self.logger.error(f"Traceback:\n{traceback.format_exc()}")
            raise

    def _init_summarizer(self) -> None:
        """Inicializa el generador de res√∫menes."""
        try:
            # Pasar el LLM al summarizer para res√∫menes abstractivos
            self.summarizer = EvidenceSummarizer(llm=self.llm)
            self.logger.info("Generador de res√∫menes inicializado")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è  Error inicializando summarizer: {e}")
            self.summarizer = None

    def retrieve_context(self, query: str) -> Tuple[str, List[Dict[str, Any]]]:
        """
        Recupera evidencia relevante de la base de datos vectorial.

        Este m√©todo usa el pipeline avanzado de recuperaci√≥n:
        1. B√∫squeda vectorial inicial (k documentos)
        2. Filtrado por metadatos enriquecidos
        3. B√∫squeda h√≠brida (sem√°ntica + keywords)
        4. Reranking con cross-encoder
        5. Diversificaci√≥n de fuentes
        6. Aplicaci√≥n de thresholds de relevancia

        Args:
            query: Consulta para b√∫squeda de evidencia

        Returns:
            Tupla con:
            - context: String formateado con evidencia y citaciones
            - metadata: Lista de metadatos de documentos recuperados
        """
        if not self.vector_db:
            self.logger.warning("No hay base de datos vectorial disponible")
            return "", []

        # Usar AdvancedRetriever si est√° disponible
        if self.advanced_retriever:
            try:
                self.logger.info("Usando pipeline avanzado de recuperacion")
                context, metadata_list = self.advanced_retriever.retrieve_with_context(query)
                self.logger.debug(f"Contexto construido con {len(metadata_list)} fragmentos (pipeline avanzado)")

                if metadata_list:
                    self.logger.debug("Documentos recuperados:")
                    for i, meta in enumerate(metadata_list[:5], 1):
                        filename = meta.get("filename", "Unknown")
                        citation = meta.get("citation", "")
                        self.logger.debug(f"\t {i}.{filename} {citation}")
                return context, metadata_list
            except Exception as e:
                self.logger.error(f"‚ùå Error en AdvancedRetriever, usando fallback: {e}")
                # Continuar con m√©todo b√°sico como fallback
                import traceback
                traceback.print_exception(e)

        # === FALLBACK: M√©todo b√°sico original ===
        self.logger.warning("‚ö†Ô∏è  Usando pipeline de recuperaci√≥n b√°sico (fallback)")

        # Configuraci√≥n RAG
        rag_config = self.config.get_rag_config()
        k_initial = rag_config.get('similarity_search', {}).get('k', 50)
        top_k_rerank = rag_config.get('reranking', {}).get('top_k', 5)

        # 1. B√∫squeda vectorial inicial
        self.logger.debug(f"Buscando documentos similares (k={k_initial})")
        docs = self.vector_db.similarity_search(query, k=k_initial)

        if not docs:
            self.logger.warning("No se encontraron documentos relevantes")
            return "", []

        self.logger.debug(f"\tEncontrados {len(docs)} documentos iniciales")

        # 2. Reranking (si est√° disponible)
        if self.reranker:
            self.logger.debug("Aplicando reranking")
            pairs = [[query, doc.page_content] for doc in docs]
            scores = self.reranker.predict(pairs)
            scored_docs = sorted(
                zip(docs, scores),
                key=lambda x: x[1],
                reverse=True
            )
            top_docs = [doc for doc, score in scored_docs[:top_k_rerank]]
            self.logger.debug(
                f"\tTop {top_k_rerank} documentos tras reranking"
            )
        else:
            top_docs = docs[:top_k_rerank]

        # 3. Construcci√≥n del contexto con citaciones
        context_parts = []
        metadata_list = []

        for doc in top_docs:
            filename = os.path.basename(doc.metadata.get("source", "Desconocido"))

            # Citaci√≥n granular
            citation = self._build_citation(doc.metadata)

            header = f"--- DOCUMENTO: {filename}{citation} ---"
            clean_content = " ".join(doc.page_content.split())

            context_parts.append(f"{header}\n{clean_content}\n")
            metadata_list.append({
                'filename': filename,
                'citation': citation,
                'metadata': doc.metadata
            })

        context = "\n".join(context_parts)
        self.logger.debug(f"Contexto construido con {len(top_docs)} fragmentos")

        return context, metadata_list

    @staticmethod
    def _build_citation(metadata: Dict[str, Any]) -> str:
        """
        Construye una citaci√≥n precisa basada en los metadatos del documento.

        Args:
            metadata: Metadatos del documento

        Returns:
            String con la citaci√≥n formateada
        """
        citation = ""

        # Si es PDF (tiene n√∫mero de p√°gina)
        if "page" in metadata:
            page_num = metadata['page'] + 1  # PyPDF usa √≠ndice 0
            citation = f" (P√°g. {page_num})"

        # Si es TXT con chunks (secciones)
        elif "chunk_id" in metadata:
            chunk_id = metadata['chunk_id']
            total_chunks = metadata.get('total_chunks_in_file', '?')
            citation = f" (Sec. {chunk_id}/{total_chunks})"

        return citation

    def _calculate_confidence(self, verdict: str, context: str, metadata_list: List[Dict[str, Any]],
                              claim: str = "", explanation: str = "") -> int:
        """
        Calcula un nivel de confianza basado en la evidencia recuperada.

        El nivel de confianza se basa en:
        - Similitud sem√°ntica entre claim y explicaci√≥n (coseno de embeddings)
        - Scores de los documentos recuperados (calidad de la evidencia)
        - N√∫mero de fuentes diversas
        - Penalizaci√≥n por explicaciones gen√©ricas
        - Coherencia entre fuentes

        Args:
            verdict: Veredicto del sistema (VERDADERO, FALSO, etc.)
            context: Contexto recuperado
            metadata_list: Metadatos de documentos recuperados
            claim: Claim original del usuario
            explanation: Explicaci√≥n generada por el LLM

        Returns:
            Nivel de confianza de 0 a 5
        """
        if verdict == "NO SE PUEDE VERIFICAR" or not context:
            return 0

        confidence_score = 0.0  # Score flotante (0-5)

        # FACTOR 1: Similitud sem√°ntica claim-explicaci√≥n (0-2 puntos)
        if claim and explanation and hasattr(self, 'embeddings'):
            try:
                # Generar embeddings para claim y explicaci√≥n
                claim_embedding = self.embeddings.embed_query(claim)
                explanation_embedding = self.embeddings.embed_query(explanation)

                # Calcular similitud coseno usando numpy
                claim_vec = np.array(claim_embedding)
                expl_vec = np.array(explanation_embedding)

                cosine_sim = np.dot(claim_vec, expl_vec) / (
                        np.linalg.norm(claim_vec) * np.linalg.norm(expl_vec)
                )

                # Convertir similitud (0-1) a puntos (0-2)
                # Alta similitud = explicaci√≥n espec√≠fica y relevante
                similarity_points = max(0, min(2.0, float(cosine_sim) * 2.5))
                confidence_score += similarity_points

                self.logger.debug(f"Similitud coseno: {cosine_sim:.4f} ‚Üí +{similarity_points:.2f} puntos")

            except Exception as e:
                self.logger.debug(f"No se pudo calcular similitud sem√°ntica: {e}")
                # Fallback: dar 1 punto base
                confidence_score += 1.0
                self.logger.debug(f"  +1.0 punto (fallback)")

        # FACTOR 2: Calidad de los documentos recuperados (0-2 puntos)
        if metadata_list:
            # Extraer scores de los metadatos (si existen)
            scores = []
            for meta in metadata_list:
                if isinstance(meta, dict) and 'score' in meta:
                    scores.append(meta['score'])

            self.logger.debug(f"Scores extra√≠dos: {scores} (de {len(metadata_list)} docs)")

            if scores:
                avg_score = sum(scores) / len(scores)
                self.logger.debug(f"Score promedio: {avg_score:.3f}")

                # Score promedio > 0.7 = alta relevancia
                if avg_score >= 0.7:
                    confidence_score += 2.0
                    self.logger.debug(f"  +2.0 puntos (score >= 0.7)")
                elif avg_score >= 0.6:
                    confidence_score += 1.5
                    self.logger.debug(f"  +1.5 puntos (score >= 0.6)")
                elif avg_score >= 0.5:
                    confidence_score += 1.0
                    self.logger.debug(f"  +1.0 punto (score >= 0.5)")
                else:
                    confidence_score += 0.5
                    self.logger.debug(f"  +0.5 puntos (score < 0.5)")
            else:
                # Sin scores, dar 1 punto base si hay documentos
                confidence_score += 1.0
                self.logger.debug(f"  +1.0 punto (sin scores, fallback)")

        # FACTOR 3: N√∫mero de fuentes √∫nicas (0-1 punto)
        num_sources = len(set(meta.get('source', '') for meta in metadata_list if isinstance(meta, dict)))
        if num_sources >= 3:
            confidence_score += 1.0
        elif num_sources >= 2:
            confidence_score += 0.5

        # PENALIZACI√ìN: Explicaciones gen√©ricas/vagas
        if explanation:
            import re
            vague_indicators = [
                r"confirma la informaci√≥n",
                r"seg√∫n la evidencia",
                r"evidencia confirma",
                r"informaci√≥n mencionada"
            ]

            explanation_lower = explanation.lower()
            vague_count = sum(1 for pattern in vague_indicators
                              if re.search(pattern, explanation_lower))

            if vague_count >= 2:
                confidence_score *= 0.7  # Penalizar 30%
                self.logger.debug(f"Penalizaci√≥n vaga (2+ patrones): x0.7 ‚Üí {confidence_score:.2f}")
            elif vague_count == 1:
                confidence_score *= 0.85  # Penalizar 15%
                self.logger.debug(f"Penalizaci√≥n vaga (1 patr√≥n): x0.85 ‚Üí {confidence_score:.2f}")

        # Convertir a escala 0-5 (entero)
        final_confidence = max(0, min(5, round(confidence_score)))
        self.logger.debug(f"üìä Confianza final: {confidence_score:.2f} ‚Üí {final_confidence}/5")

        return final_confidence

    @staticmethod
    def _reduce_context(claim: str, context: str, max_sentences: int = 10) -> str:
        """
        Reduce el contexto a las frases m√°s ancla para el claim.

        Criterios gen√©ricos (no dependientes de dominio):
        - Coincidencia de entidades del claim (palabras capitalizadas de 2+ t√©rminos o tokens significativos)
        - Coincidencia de verbo/acci√≥n com√∫n (fund√≥/cre√≥/gan√≥/...)
        - Presencia de n√∫meros de 4 d√≠gitos (a√±os)

        Args:
            claim: Afirmaci√≥n del usuario (en espa√±ol preferentemente)
            context: Contexto completo concatenado de m√∫ltiples documentos
            max_sentences: M√°ximo de frases a retornar

        Returns:
            Subconjunto de frases relevantes concatenadas, preservando encabezados de documento
        """
        import re

        if not context:
            return context

        # Extraer entidades simples del claim (palabras capitalizadas compuestas o tokens > 3 chars)
        entities = set()
        entities.update(re.findall(r"\b([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)*)\b", claim))
        # A√±adir keywords en min√∫scula significativas del claim
        entities.update([w for w in re.findall(r"\b\w{4,}\b", claim.lower()) if not w.isdigit()])

        # Verbos/acciones comunes en verificaci√≥n de hechos (gen√©rico en espa√±ol)
        action_terms = {
            'fundado', 'fundaci√≥n', 'creado', 'creaci√≥n', 'establecido', 'registrado',
            'gan√≥', 'ganar', 'victoria', 'campe√≥n', 't√≠tulo', 'obtuvo', 'logr√≥', 'consigui√≥',
            'naci√≥', 'muerte', 'falleci√≥', 'es', 'fue', 'fueron', 'son'
        }

        # Dividir en bloques por documento para preservar encabezados
        blocks = re.split(r"(--- DOCUMENTO\s+\d+: .*?---)", context)
        reduced_parts: List[str] = []
        selected_count = 0

        def score_sentence(s: str) -> int:
            s_low = s.lower()
            score = 0
            # Entidades/keywords
            score += sum(1 for e in entities if e and e.lower() in s_low)
            # Verbos/acciones
            score += sum(1 for a in action_terms if a in s_low)
            # A√±os
            if re.search(r"\b(1[89]\d{2}|20\d{2})\b", s):
                score += 2
            return score

        for i in range(0, len(blocks), 2):
            header = blocks[i]
            body = blocks[i + 1] if i + 1 < len(blocks) else ''
            if header and header.strip().startswith('--- DOCUMENTO'):
                reduced_parts.append(header.strip())
                continue

            text = header if header else body
            if not text or text.strip().startswith('--- DOCUMENTO'):
                continue

            # Dividir a oraciones de forma sencilla
            sentences = re.split(r"(?<=[\.!?])\s+", text)
            # Puntuar y seleccionar top
            scored = [(s, score_sentence(s)) for s in sentences if len(s.strip()) > 20]
            scored.sort(key=lambda x: x[1], reverse=True)

            for s, sc in scored:
                if sc <= 0:
                    continue
                reduced_parts.append(s.strip())
                selected_count += 1
                if selected_count >= max_sentences:
                    break
            if selected_count >= max_sentences:
                break

        # Si no se seleccion√≥ nada, devolver primeras frases razonables
        if selected_count == 0:
            sentences = re.split(r"(?<=[\.!?])\s+", context)
            fallback = [s.strip() for s in sentences if len(s.strip()) > 20][:max_sentences]
            return "\n".join(fallback)

        return "\n".join(reduced_parts)

    @staticmethod
    def _match_keyword_group(text: str, keyword_map: Dict[str, Dict[str, Tuple[str, ...]]]) -> Optional[Dict[str, str]]:
        """Detecta si el texto contiene alguna palabra clave definida en un diccionario."""
        if not text:
            return None

        text_lower = text.lower()
        for key, data in keyword_map.items():
            for keyword in data.get('keywords', ()):  # type: ignore[arg-type]
                if keyword and keyword in text_lower:
                    return {
                        "key": key,
                        "display": data.get('display', key.replace('_', ' ').title()),
                        "matched": keyword
                    }
        return None

    def _apply_domain_guard(self, claim: str) -> Optional[Dict[str, Any]]:
        """Aplica una guard clause cuando el claim se sale del dominio cubierto."""
        supported_hit = self._match_keyword_group(claim, self.SUPPORTED_TEAM_KEYWORDS)
        if supported_hit:
            return None

        self.logger.warning("üõë Claim fuera de dominio detectado")

        message = (
            "El corpus actual solo cubre clubes madrile√±os (Real Madrid, Atl√©tico, Getafe, "
            "Legan√©s y Rayo Vallecano). No hay evidencia interna para verificar hechos sobre."
        )

        return {
            "veredicto": "NO SE PUEDE VERIFICAR",
            "nivel_confianza": 0,
            "fuente_documento": "Fuera del dominio del corpus",
            "explicacion_corta": message,
            "evidencia_citada": "Ninguna",
            "fragmentos_evidencia": [],
            "fuentes": [],
            "resumen_evidencia": "No disponible"
        }

    def _apply_structured_rules(self, claim: str, context: str,
                                metadata_list: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """Aplica reglas determin√≠sticas antes de invocar al LLM."""
        override = self._detect_foundation_year_override(claim, context, metadata_list)
        if override:
            return override
        return None

    def _detect_foundation_year_override(self, claim: str, context: str,
                                         metadata_list: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """Detecta contradicciones expl√≠citas sobre el a√±o de fundaci√≥n."""
        import re

        if not claim or not context:
            return None

        claim_lower = claim.lower()
        if not any(token in claim_lower for token in ("fundad", "fundaci√≥n", "fundacion", "registrad", "registro")):
            return None

        claim_year_match = re.search(r"(1[89]\d{2}|20\d{2})", claim_lower)
        if not claim_year_match:
            return None
        claim_year = claim_year_match.group(1)

        team_hit = self._match_keyword_group(claim, self.SUPPORTED_TEAM_KEYWORDS)
        if not team_hit:
            return None

        keywords = tuple(keyword for keyword in self.SUPPORTED_TEAM_KEYWORDS[team_hit['key']]['keywords'])
        # Patr√≥n mejorado: solo acepta a√±os MUY cercanos (m√°x 30 caracteres) a palabras de fundaci√≥n
        # Esto evita falsos positivos como "club fundado... que en 1947 hizo X"
        foundation_pattern = re.compile(
            r"(?:fundad[oa]|registrad[oa]|inscrito|constituy[o√≥]|legaliz[a√≥]|acta).{0,30}?((?:18|19|20)\d{2})",
            re.IGNORECASE
        )

        sentences = re.split(r"(?<=[\.!?])\s+", context)
        evidence_candidates: List[Tuple[str, str]] = []

        for sentence in sentences:
            cleaned = sentence.strip()
            if not cleaned:
                continue

            sentence_lower = cleaned.lower()
            if not any(keyword in sentence_lower for keyword in keywords):
                continue
            if not any(token in sentence_lower for token in ("fundad", "fundaci√≥n", "fundacion", "registr", "acta", "legaliz")):
                continue

            for match in foundation_pattern.finditer(cleaned):
                year = match.group(1)
                # Filtro adicional: verificar que el a√±o est√© en contexto directo de fundaci√≥n
                # Buscar 50 caracteres antes y despu√©s del a√±o encontrado
                match_start = match.start(1)
                context_window = cleaned[max(0, match_start - 50):min(len(cleaned), match_start + 50)].lower()

                # Rechazar si hay palabras que indican otros eventos (no fundaci√≥n)
                exclusion_keywords = ["acuerdo", "contrato", "filial", "fichaje", "traspaso", "convenio"]
                if any(excl in context_window for excl in exclusion_keywords):
                    continue

                evidence_candidates.append((year, cleaned))

        if not evidence_candidates:
            return None

        year_counter = Counter(year for year, _ in evidence_candidates)
        if not year_counter:
            return None

        best_year, _ = year_counter.most_common(1)[0]
        if best_year == claim_year:
            return None

        best_sentence = next((sentence for year, sentence in evidence_candidates if year == best_year), "")

        first_source = metadata_list[0] if metadata_list else {}
        source_label = first_source.get('filename', 'Documentaci√≥n del corpus')
        citation = first_source.get('citation', '')
        if citation:
            source_label = f"{source_label}{citation}"

        self.logger.info(
            f"‚öñÔ∏è Regla de fundaci√≥n aplicada: {team_hit['display']} ‚Üí {best_year} (claim dec√≠a {claim_year})"
        )

        return {
            "veredicto": "FALSO",
            "nivel_confianza": 4,
            "fuente_documento": source_label,
            "explicacion_corta": (
                f"La documentaci√≥n indica que {team_hit['display']} se fund√≥ oficialmente en {best_year}, "
                f"no en {claim_year}."
            ),
            "evidencia_citada": best_sentence or "La fuente primaria menciona el a√±o correcto de fundaci√≥n."
        }

    def verify(self, claim_usuario: str) -> Dict[str, Any]:
        """
        Verifica la veracidad de una afirmaci√≥n.

        Este es el m√©todo principal del sistema. Proceso completo:
        1. Detecta idioma y traduce a espa√±ol si es necesario
        2. Verifica cach√© para consultas repetidas
        3. Recupera evidencia de la base de datos
        4. Eval√∫a con el LLM
        5. Traduce respuesta al idioma original
        6. Retorna resultado con m√©tricas

        Args:
            claim_usuario: Afirmaci√≥n a verificar (en cualquier idioma)

        Returns:
            Diccionario con:
            - veredicto: VERDADERO, FALSO, o NO SE PUEDE VERIFICAR
            - nivel_confianza: 0-5
            - fuente_documento: Archivo(s) que respaldan el veredicto
            - explicacion_corta: Justificaci√≥n del veredicto
            - evidencia_citada: Fragmento relevante de la evidencia
            - fuentes: Lista de fuentes con citaciones
            - fragmentos_evidencia: Lista de fragmentos recuperados
            - tiempo_procesamiento: Tiempo total en segundos
            - origen: LLM o CACH√â
            - idioma_respuesta: Idioma de la respuesta
            - calidad_traduccion: % de confianza en la traducci√≥n
        """
        start_time = time.time()
        self.logger.info("=" * 70)
        self.logger.info(f"Nueva verificaci√≥n: '{claim_usuario[:100]}...'")

        # --- PASO 1: PROCESAMIENTO DE IDIOMA ---
        claim_es, idioma_orig, calidad = self._process_input_language(
            claim_usuario
        )

        # --- PASO 2: GUARD CLAUSE DE DOMINIO ---
        guard_result = self._apply_domain_guard(claim_es)

        if guard_result:
            result = guard_result
            origen = "GUARD_CLAUSE"
        else:
            # --- PASO 3: VERIFICAR CACH√â ---
            claim_hash = self._get_cache_key(claim_es)
            cached_result = self._check_cache(claim_hash)

            if cached_result:
                result = cached_result
                origen = "CACH√â"
                self.logger.info("Resultado obtenido de cach√©")
            else:
                # --- PASO 4: RECUPERAR EVIDENCIA ---
                self.logger.debug(f"Buscando evidencia para: {claim_es}")
                context, metadata_list = self.retrieve_context(claim_es)

                if context:
                    context_preview = context[:500].replace('\n', ' ')
                    self.logger.debug(f"Contexto recuperado: {context_preview}")
                    self.logger.debug(f"Recuperados {len(metadata_list)} fragmentos de evidencia")
                else:
                    self.logger.warning(f"‚ö†Ô∏è No se recuper√≥ ning√∫n contexto")

                # --- PASO 4BIS: APLICAR REGLAS DETERMIN√çSTICAS ---
                structured_override = self._apply_structured_rules(
                    claim_es,
                    context,
                    metadata_list
                ) if context else None

                if structured_override:
                    result = structured_override
                else:
                    # --- PASO 5: EVALUAR CON LLM ---
                    result = self._evaluate_claim(
                        claim_es,
                        claim_usuario,
                        context,
                        calidad,
                        metadata_list
                    )

                # --- PASO 5.5: AGREGAR FUENTES Y FRAGMENTOS ---
                result['fuentes'] = self._format_sources(metadata_list)
                result['fragmentos_evidencia'] = self._extract_evidence_fragments(context, metadata_list)

                # --- PASO 5.6: GENERAR RESUMEN (si hay fragmentos) ---
                if self.summarizer and result['fragmentos_evidencia']:
                    try:
                        resumen = self.summarizer.generate_summary(
                            result['fragmentos_evidencia'],
                            claim_es,
                            method="extractive",
                            max_sentences=2
                        )
                        result['resumen_evidencia'] = resumen
                        self.logger.debug(f"Resumen generado: {resumen[:100]}...")
                    except Exception as e:
                        self.logger.warning(f"‚ö†Ô∏è  Error generando resumen: {e}")
                        result['resumen_evidencia'] = "No disponible"

                # --- PASO 6: GUARDAR EN CACH√â ---
                self._save_to_cache(claim_hash, result)
                origen = "LLM"

        # --- PASO 6: TRADUCIR RESPUESTA ---
        final_result = self._translate_response(result, idioma_orig)

        # --- PASO 7: A√ëADIR M√âTRICAS ---
        tiempo_total = round(time.time() - start_time, 3)
        final_result.update({
            "tiempo_procesamiento": f"{tiempo_total}s",
            "origen": origen,
            "calidad_traduccion": f"{int(calidad * 100)}%",
            "idioma_respuesta": idioma_orig
        })

        self.logger.info(f"‚úÖ Verificaci√≥n completada en {tiempo_total}s")
        self.logger.info(f"\tVeredicto: {final_result.get('veredicto')}")
        self.logger.info(f"\tConfianza: {final_result.get('nivel_confianza')}/5")
        self.logger.info("=" * 70)

        return final_result

    def _process_input_language(self, claim_usuario: str) -> Tuple[str, str, float]:
        """
        Procesa el idioma de entrada y traduce si es necesario.

        Args:
            claim_usuario: Afirmaci√≥n original del usuario

        Returns:
            Tupla con (claim_en_espa√±ol, idioma_original, calidad_traducci√≥n)
        """
        if self.linguist:
            claim_es, idioma_orig, calidad = self.linguist.procesar_entrada(
                claim_usuario
            )
            self.logger.info(f"Idioma detectado: {idioma_orig}")
            if idioma_orig != 'es':
                self.logger.info(f"\tTraducci√≥n realizada (calidad: {int(calidad * 100)}%)")
            return claim_es, idioma_orig, calidad
        else:
            # Sin procesador de idiomas, asumir espa√±ol
            return claim_usuario, 'es', 1.0

    @staticmethod
    def _get_cache_key(claim: str) -> str:
        """
        Genera una clave de cach√© para una afirmaci√≥n.

        Args:
            claim: Afirmaci√≥n normalizada

        Returns:
            Hash MD5 de la afirmaci√≥n
        """
        normalized = claim.lower().strip()
        return hashlib.md5(normalized.encode()).hexdigest()

    def _check_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """
        Verifica si existe un resultado en cach√©.

        Args:
            cache_key: Clave de cach√©

        Returns:
            Resultado cacheado o None
        """
        if self.cache is not None and cache_key in self.cache:
            self.logger.debug(f"Cache HIT: {cache_key[:8]}...")
            return self.cache[cache_key].copy()
        return None

    def _save_to_cache(self, cache_key: str, result: Dict[str, Any]) -> None:
        """
        Guarda un resultado en cach√©.

        Args:
            cache_key: Clave de cach√©
            result: Resultado a guardar
        """
        if self.cache is not None:
            # Gesti√≥n de tama√±o m√°ximo (FIFO simple)
            if len(self.cache) >= self.cache_max_size:
                # Eliminar el primer elemento
                first_key = next(iter(self.cache))
                del self.cache[first_key]

            self.cache[cache_key] = result.copy()
            self.logger.debug(f"Guardado en cach√©: {cache_key[:8]}...")

    @staticmethod
    def _check_context_relevance(claim: str, context: str) -> float:
        """
        Verifica si el contexto es relevante para la afirmaci√≥n usando similitud b√°sica.

        Args:
            claim: Afirmaci√≥n a verificar
            context: Contexto recuperado

        Returns:
            Score de relevancia (0.0 a 1.0)
        """
        if not context or not claim:
            return 0.0

        # Extraer palabras clave de la afirmaci√≥n (simple)
        claim_words = set(claim.lower().split())
        context_lower = context.lower()

        # Contar cu√°ntas palabras clave aparecen en el contexto
        matches = sum(1 for word in claim_words if len(word) > 3 and word in context_lower)
        relevance = matches / max(len([w for w in claim_words if len(w) > 3]), 1)

        return min(relevance, 1.0)

    @staticmethod
    def _validate_llm_response(result: Dict[str, Any], claim: str, context: str) -> Dict[str, Any]:
        """
        Valida la respuesta del LLM para detectar alucinaciones.

        Verifica que la explicaci√≥n del LLM sea consistente con el claim.
        Por ejemplo, si el claim dice "1902" pero la explicaci√≥n habla de "1950",
        es una alucinaci√≥n.

        Args:
            result: Respuesta del LLM
            claim: Afirmaci√≥n original
            context: Contexto usado

        Returns:
            Resultado validado (o corregido si es necesario)
        """
        import re

        # Extraer explicaci√≥n
        explicacion = result.get('explicacion_corta', '')

        # Extraer a√±os del claim y de la explicaci√≥n
        claim_years = set(re.findall(r'\b(1[89]\d{2}|20\d{2})\b', claim))
        expl_years = set(re.findall(r'\b(1[89]\d{2}|20\d{2})\b', explicacion))

        # Si la explicaci√≥n menciona a√±os que NO est√°n en el claim, es sospechoso
        extra_years = expl_years - claim_years

        if extra_years and result.get('veredicto') == 'FALSO':
            # El LLM est√° comparando con un a√±o que no est√° en el claim
            # Esto indica confusi√≥n - probablemente deber√≠a ser VERDADERO o NO SE PUEDE VERIFICAR

            # Verificar si el a√±o del claim S√ç aparece en el contexto
            context_years = set(re.findall(r'\b(1[89]\d{2}|20\d{2})\b', context))

            if claim_years and claim_years.intersection(context_years):
                # El a√±o del claim S√ç est√° en el contexto ‚Üí deber√≠a ser VERDADERO
                return {
                    "veredicto": "VERDADERO",
                    "nivel_confianza": 4,
                    "fuente_documento": result.get('fuente_documento', 'Corregido por validaci√≥n'),
                    "explicacion_corta": f"La evidencia confirma la informaci√≥n mencionada en la afirmaci√≥n.",
                    "evidencia_citada": result.get('evidencia_citada', 'Validado por sistema')
                }

        # Si no hay problema, devolver el resultado original
        return result

    @staticmethod
    def _validate_vague_explanations(result: Dict[str, Any], claim: str, context: str) -> Dict[str, Any]:
        """
        Detecta explicaciones vagas y convierte VERDADERO ‚Üí NO SE PUEDE VERIFICAR cuando corresponde.

        Ejemplos de explicaciones vagas:
        - "La evidencia confirma la informaci√≥n mencionada en la afirmaci√≥n." (sin especificar QU√â)
        - "La evidencia confirma que [X]" pero X NO es el sujeto principal del claim

        Args:
            result: Resultado del LLM
            claim: Claim original
            context: Contexto recuperado

        Returns:
            Resultado validado
        """
        import re

        verdict = result.get('veredicto', '')
        explanation = result.get('explicacion_corta', '')

        # Solo validar si el veredicto es VERDADERO
        if verdict != "VERDADERO":
            return result

        # Patrones de explicaciones gen√©ricas/vagas
        vague_patterns = [
            r"la evidencia confirma la informaci√≥n mencionada en la afirmaci√≥n",
            r"la evidencia confirma que.{0,50}$",  # Muy corta
            r"confirma la informaci√≥n",
            r"la evidencia valida",
        ]

        explanation_lower = explanation.lower()
        is_vague = any(re.search(pattern, explanation_lower) for pattern in vague_patterns)

        if is_vague:
            # Verificar si el claim menciona un sujeto espec√≠fico que NO est√° en el contexto
            # Ejemplo: Claim "El Atl√©tico de Madrid es madrile√±o" pero contexto solo menciona
            # "derbi madrile√±o" entre Real Madrid y Atl√©tico (no describe al Atl√©tico directamente)

            # Extraer sujeto principal del claim (primera entidad capitalizada)
            match = re.search(
                r"(El|La|Los|Las)\s+([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[a-z√°√©√≠√≥√∫√±]+)*(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)*)",
                claim)
            if match:
                subject = match.group(2).strip()

                # Verificar si el contexto DESCRIBE al sujeto (no solo lo menciona)
                # Buscar patrones como "X es", "X fue", "X tiene", etc.
                descriptive_patterns = [
                    rf"{re.escape(subject)}\s+(es|fue|tiene|cuenta con|se fund√≥|fundado)",
                    rf"sobre\s+{re.escape(subject)}",
                    rf"historia\s+de\s+{re.escape(subject)}",
                ]

                has_description = any(re.search(pattern, context, re.IGNORECASE)
                                      for pattern in descriptive_patterns)

                if not has_description:
                    # √öLTIMO CHECK: ¬øEl claim pregunta algo gen√©rico como "es madrile√±o"?
                    # Si el contexto menciona al sujeto en contexto de Madrid, podr√≠a ser v√°lido
                    if "madrid" in claim.lower() and subject.lower() in context.lower():
                        # Es un caso l√≠mite - dejarlo pasar
                        return result

                    # Definitivamente vago
                    return {
                        "veredicto": "NO SE PUEDE VERIFICAR",
                        "nivel_confianza": 0,
                        "fuente_documento": result.get('fuente_documento', 'Corregido por validaci√≥n'),
                        "explicacion_corta": f"La evidencia menciona '{subject}' de pasada pero no describe sus caracter√≠sticas directamente.",
                        "evidencia_citada": result.get('evidencia_citada', 'Validado por sistema')
                    }

        return result

    def _evaluate_claim(self, claim_es: str, claim_original: str, context: str, translation_quality: float,
                        metadata_list: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Eval√∫a una afirmaci√≥n usando el LLM.

        Args:
            claim_es: Afirmaci√≥n en espa√±ol
            claim_original: Afirmaci√≥n original del usuario
            context: Contexto recuperado
            translation_quality: Calidad de la traducci√≥n (0-1)
            metadata_list: Metadatos de documentos recuperados

        Returns:
            Diccionario con el veredicto y detalles
        """
        # Si no hay contexto, no se puede verificar
        if not context:
            self.logger.warning("‚ùå No se encontr√≥ contexto relevante")
            return {
                "veredicto": "NO SE PUEDE VERIFICAR",
                "explicacion_corta": "No se encontr√≥ informaci√≥n relevante en la base de datos.",
                "fuente_documento": "Ninguno",
                "nivel_confianza": 0,
                "evidencia_citada": "Ninguna"
            }

        # NUEVA VALIDACI√ìN: Verificar relevancia del contexto
        relevance_score = self._check_context_relevance(claim_es, context)
        self.logger.debug(f"Relevancia del contexto: {relevance_score:.2f}")

        if relevance_score < 0.30:  # Umbral m√°s exigente de relevancia
            self.logger.warning(
                f"‚ö†Ô∏è Contexto poco relevante (score: {relevance_score:.2f}). Reintentando retrieval sin n√∫meros...")

            # Fallback gen√©rico: intentar recuperar usando la query sin n√∫meros/fechas
            import re as _re
            claim_topic_only = _re.sub(r"\b\d+\b", " ", claim_es)
            claim_topic_only = " ".join(claim_topic_only.split())

            new_context, new_metadata = self.retrieve_context(claim_topic_only)
            if new_context:
                self.logger.debug("üîÅ Fallback: contexto alternativo recuperado para evaluaci√≥n")
                context = new_context
                metadata_list = new_metadata
            else:
                self.logger.warning("üîÅ Fallback sin resultados. Se devuelve NO SE PUEDE VERIFICAR")
                return {
                    "veredicto": "NO SE PUEDE VERIFICAR",
                    "explicacion_corta": "La evidencia encontrada no trata sobre el tema de la afirmaci√≥n.",
                    "fuente_documento": "Ninguno",
                    "nivel_confianza": 0,
                    "evidencia_citada": "Ninguna"
                }

        # Preparar prompt con advertencia de traducci√≥n si aplica
        prompt_claim = claim_es
        threshold = self.config.get(
            'language.translation_confidence_threshold',
            0.6
        )

        if translation_quality < threshold:
            self.logger.warning(
                f"‚ö†Ô∏è  Calidad de traducci√≥n baja ({int(translation_quality * 100)}%)"
            )
            prompt_claim += (
                f" [NOTA: Posible error de traducci√≥n. "
                f"Original: '{claim_original}']"
            )

        # Usar contexto completo (top 3 chunks) sin reducci√≥n
        context_to_send = context
        self.logger.info(f"üìÑ Usando contexto completo sin reducci√≥n ({len(context)} caracteres)")
        self.logger.debug(f"Contexto enviado al LLM (preview): {context_to_send[:500]}...")

        # Invocar al LLM
        self.logger.info("Evaluando con LLM...")
        try:
            # Verificar que self.chain existe
            if not hasattr(self, 'chain') or self.chain is None:
                raise RuntimeError(
                    "La cadena de procesamiento (self.chain) no est√° disponible. "
                    "El sistema no se inicializ√≥ correctamente."
                )

            result = self.chain.invoke({
                "context": context,
                "claim": prompt_claim
            })

            # POST-PROCESAMIENTO: Validar respuesta del LLM
            # Si el LLM da una explicaci√≥n que menciona fechas/datos que no est√°n en el claim,
            # es una alucinaci√≥n y debemos corregir
            result = self._validate_llm_response(result, claim_es, context)

            # NUEVA VALIDACI√ìN: Detectar explicaciones vagas que indican falta de evidencia
            result = self._validate_vague_explanations(result, claim_es, context)

            # Calcular confianza basada en evidencia
            if 'nivel_confianza' not in result or result['nivel_confianza'] == 0:
                result['nivel_confianza'] = self._calculate_confidence(
                    verdict=result.get('veredicto', ''),
                    context=context,
                    metadata_list=metadata_list,
                    claim=claim_es,
                    explanation=result.get('explicacion_corta', '')
                )

            return result

        except Exception as e:
            self.logger.error(f"‚ùå Error en evaluaci√≥n con LLM: {e}")
            import traceback
            self.logger.error(f"Traceback completo:\n{traceback.format_exc()}")
            return {
                "error": f"Fallo del modelo: {str(e)}",
                "veredicto": "ERROR",
                "nivel_confianza": 0
            }

    def _translate_response(self, result: Dict[str, Any], target_language: str) -> Dict[str, Any]:
        """
        Traduce la respuesta al idioma objetivo.

        Args:
            result: Resultado en espa√±ol
            target_language: Idioma objetivo

        Returns:
            Resultado traducido
        """
        if target_language == 'es' or not self.linguist:
            return result.copy()

        translated_result = result.copy()

        # Traducir campos de texto
        if 'explicacion_corta' in translated_result:
            translated_result['explicacion_corta'] = self.linguist.procesar_salida(
                translated_result['explicacion_corta'],
                target_language
            )

        if 'veredicto' in translated_result:
            translated_result['veredicto'] = self.linguist.procesar_salida(
                translated_result['veredicto'],
                target_language
            )

        # La evidencia citada NO se traduce para mantener fidelidad
        self.logger.debug(f"üåç Respuesta traducida a: {target_language}")

        return translated_result

    @staticmethod
    def _format_sources(metadata_list: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """
        Formatea la lista de metadatos en fuentes legibles.

        Args:
            metadata_list: Lista de metadatos de documentos

        Returns:
            Lista de diccionarios con informaci√≥n de fuentes
        """
        sources = []
        for meta in metadata_list:
            source = {
                'documento': meta.get('filename', 'Desconocido'),
                'citacion': meta.get('citation', ''),
                'seccion': meta.get('metadata', {}).get('chunk_id', ''),
            }
            sources.append(source)
        return sources

    @staticmethod
    def _extract_evidence_fragments(context: str, metadata_list: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """
        Extrae fragmentos de evidencia del contexto con sus metadatos.

        Args:
            context: Contexto completo
            metadata_list: Lista de metadatos

        Returns:
            Lista de fragmentos con informaci√≥n
        """
        import re

        fragments = []
        # Dividir el contexto por documentos
        doc_parts = re.split(r'(--- DOCUMENTO \d+:.*?---)', context)

        for i, meta in enumerate(metadata_list, 1):
            # Buscar el fragmento correspondiente
            fragment_text = ""
            for j in range(len(doc_parts)):
                if f"DOCUMENTO {i}:" in doc_parts[j]:
                    # El texto est√° en la siguiente parte
                    if j + 1 < len(doc_parts):
                        fragment_text = doc_parts[j + 1].strip()[:300]  # Primeros 300 chars
                    break

            if fragment_text:
                fragments.append({
                    'documento': meta.get('filename', 'Desconocido'),
                    'citacion': meta.get('citation', ''),
                    'fragmento': fragment_text
                })

        return fragments

    def get_stats(self) -> Dict[str, Any]:
        """
        Obtiene estad√≠sticas del sistema.

        Returns:
            Diccionario con estad√≠sticas:
            - cache_size: N√∫mero de elementos en cach√©
            - vector_db_docs: N√∫mero de documentos en la BD
            - config: Configuraci√≥n actual
        """
        stats = {
            'cache_size': len(self.cache) if self.cache else 0,
            'cache_max_size': self.cache_max_size if self.cache else 0,
            'vector_db_connected': self.vector_db is not None,
            'reranker_available': self.reranker is not None,
            'multilingual_enabled': self.linguist is not None
        }

        if self.vector_db:
            try:
                stats['vector_db_docs'] = self.vector_db._collection.count()
            except Exception as e:
                stats['vector_db_docs'] = 'N/A'
                self.logger.warning(f"Error while {e}")

        return stats
